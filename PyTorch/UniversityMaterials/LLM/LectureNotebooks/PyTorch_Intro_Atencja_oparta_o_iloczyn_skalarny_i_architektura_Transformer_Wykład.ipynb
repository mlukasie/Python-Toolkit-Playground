{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Atencja oparta o iloczyn skalarny i architektura Transformer"
      ],
      "metadata": {
        "id": "aOHW7E1kDkGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Atencja oparta o iloczyn skalarny\n",
        "\n",
        "**Atencja oparta o iloczyn skalarny** (*dot-product attention*) jest mechanizmem atencji stosowanym w architekturze Transformer.\n",
        "Mechanizm atencji pozwala przekształcić każdy wektor reprezentacji (osadzenie) biorąc pod uwagę szerszy kontekst, czyli wszystkie pozostałe wektory w sekwencji.\n",
        "W przypadku **auto-atencji** (*auto-attention*) brane są pod uwagę wektory w tej samej sekwencji. W przypadku **atencji krzyżowej** (*cross-attention*) kontekst stanowi inna sekwencja.\n",
        "W zastosowaniach związanych z przetwarzaniem tekstów w języku naturalnym umożliwia to tworzenie kontekstowych reprezentacji słów/tokenów biorących pod uwagę kontekst w jakim występują."
      ],
      "metadata": {
        "id": "w3IoM0f19R0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Załóżmy, że mamy sekwencję $n$ wektorów, na przykład wektorowych reprezentacji słów/tokenów, $x_1, \\ldots, x_n$, gdzie $x_i \\in \\mathbb{R}^{d}$.\n",
        "\n",
        "**W mechanizmie auto-atencji opartej o iloczyn skalarny** dla każdego wektora $x_i$ wyznaczane są wartości:\n",
        "*   **zapytania** $q_i = x_i W_q$\n",
        "*   **klucza** $k_i = x_i W_k$\n",
        "*   **wartości** $v_i = x_i W_v$\n",
        "\n",
        "$W_q, W_k, W_v \\in \\mathbb{R}^{d \\times d}$ są macierzami projekcji. Macierze projekcji są parametrami (wagami) warstwy atencji - są inicjalizowane losowo i optymalizowane w procesie uczenia modelu.\n",
        "\n",
        "Wyznaczanie zapytania, klucza i wartości dla każdego elementu sekwencji możemy zapisać w formie macierzowej.\n",
        "Niech $X \\in \\mathbb{R}^{n \\times d}$ będzie macierzą złożoną z wejściowych wektorów:\n",
        "$$\n",
        "X = \\left(\n",
        "\\begin{align}\n",
        "x_1 \\\\\n",
        "\\vdots \\\\\n",
        "x_n \\\\\n",
        "\\end{align}\n",
        "\\right)\n",
        "$$\n",
        "**Wówczas macierze złożone z wektorów zapytań, kluczy i wartości** wyznaczamy jako:\n",
        "$$\n",
        "Q = X W_q \\\\\n",
        "K = X W_k \\\\\n",
        "V = X W_v\n",
        "$$\n",
        "\n",
        "**Atencja oparta o iloczyn skalarny** zdefiniowana jest wzorem:\n",
        "$$\n",
        "\\textrm{Attention}(Q, K, V) = \\textrm{softmax} \\left( \\frac{QK^T}{\\sqrt d} \\right) V\n",
        "$$\n",
        "Wynik $\\textrm{Attention}(Q, K, V)$ jest macierzą identycznego rozmiaru jak wejściowa macierz $X$ i zawiera zaktualizowane wartości wektorów z wejściowej sekwencji z uwzględnieniem kontekstu (wartości wszystkich pozostałych wektorów w sekwencji).\n",
        "\n",
        "Wyznaczanie wyniku atencji składa się następujących kroków:\n",
        "*  Krok 1: Wyznaczenie **współczynników atencji** (*attention scores*) mierzących podobieństwo między wektorami zapytań ($Q$) i kluczy ($K$) jako skalowanego iloczynu skalarnego $\\frac{QK^T}{\\sqrt d_k}$. Współczynnik skalujący $\\frac{1}{\\sqrt d_k}$ ogranicza wartości będące argumentami funkcji softmax. $d$ oznacza rozmiar wektora klucza czyli liczbę kolumn macierzy $K$.\n",
        "*  Krok 2: Zastosowanie funkcji softmax aby wyznaczyć macierz **wag atencji** której wiersze sumują się do jedności.\n",
        "*  Krok 3: Wyznaczenie wynikowych wartości, jako sum wektorów wartości ($V$) ważonych wagami atencji."
      ],
      "metadata": {
        "id": "avt4Vz1bLU_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "qdGqQMd4_f2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(44)\n",
        "\n",
        "seq_length = 4\n",
        "d = 6\n",
        "\n",
        "# Utwórz losowy tensor wejściowy zawierający sekwencję seq_length=4 złożoną z wektorów rozmiaru d=6\n",
        "print(\"Macierz X\")\n",
        "X = torch.rand(seq_length, d)\n",
        "print(X)\n",
        "print(f\"{X.shape=}\\n\")\n",
        "\n",
        "# Do celów poglądowych utworzymy losowe macierze projekcji W_q, W_k, W_v zainicjalizowne rozkładem normalnym\n",
        "W_q = torch.randn(d, d)\n",
        "W_k = torch.randn(d, d)\n",
        "W_v = torch.randn(d, d)\n",
        "\n",
        "# Wyznacz macierze Q, K, V\n",
        "Q = torch.matmul(X, W_q)\n",
        "K = torch.matmul(X, W_k)\n",
        "V = torch.matmul(X, W_v)\n",
        "\n",
        "print(f\"{Q.shape=}\")\n",
        "print(f\"{K.shape=}\")\n",
        "print(f\"{V.shape=}\")"
      ],
      "metadata": {
        "id": "9E7G8i_r9R47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Krok 1:** Wyznacz współczynniki atencji"
      ],
      "metadata": {
        "id": "Nhm9O-SB9R9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = Q.size(-1)\n",
        "att_scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d))"
      ],
      "metadata": {
        "id": "TvmP9Ei19SCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Współczynniki atencji\")\n",
        "print(att_scores)\n",
        "\n",
        "print(f\"Suma elementów w wierszach: {att_scores.sum(dim=-1)}\")\n",
        "print(f\"{att_scores.shape=}\")\n",
        "\n",
        "# Sprawdzenie poprawności wyznaczenia współczynników atencji\n",
        "assert att_scores.shape == (seq_length, seq_length)\n",
        "assert torch.isclose(att_scores[0,0], torch.tensor(2.1263), atol=1e-04)\n",
        "assert torch.isclose(att_scores[1,2], torch.tensor(1.1623), atol=1e-04)"
      ],
      "metadata": {
        "id": "TNhanaXnZB9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Krok 2**: Zastosuj softmax aby wyznaczyć macierz wag atencji której wiersze sumują się do jedności."
      ],
      "metadata": {
        "id": "VYh3yhnK-QYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "att_weights = F.softmax(att_scores, dim=-1)"
      ],
      "metadata": {
        "id": "MNFnhl8k-Qf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Wagi atencji\")\n",
        "print(att_weights)\n",
        "\n",
        "print(f\"Suma elementów w wierszach: {att_weights.sum(dim=-1)}\")\n",
        "print(f\"{att_weights.shape=}\")\n",
        "\n",
        "# Sprawdzenie poprawności wyznaczenia współczynników atencji\n",
        "assert att_weights.shape == (seq_length, seq_length)\n",
        "assert torch.allclose(att_weights.sum(dim=-1), torch.ones_like(att_weights.sum(dim=-1)))"
      ],
      "metadata": {
        "id": "wMoCL9nzdljZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Krok 3**:\n",
        "\n",
        "Wyznaczenie wynikowych wartości, jako sum wektorów wartości (V) ważonych wagami atencji."
      ],
      "metadata": {
        "id": "La9zIHwm-QmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z = torch.matmul(att_weights, V)"
      ],
      "metadata": {
        "id": "FBwXIjXQ-Qrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Wejściowa macierz X\")\n",
        "print(X)\n",
        "print(f\"\\nMacierz wartości V\")\n",
        "print(V)\n",
        "print(f\"\\nWynikowa macierz Z\")\n",
        "print(Z)\n",
        "\n",
        "# Sprawdzenie poprawności wyznaczenia współczynników atencji\n",
        "assert Z.shape == X.shape\n",
        "assert torch.isclose(Z[0,0], torch.tensor(0.1211), atol=1e-04)\n",
        "assert torch.isclose(Z[1,2], torch.tensor(1.5165), atol=1e-04)"
      ],
      "metadata": {
        "id": "RZfSelERebPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Połącz napisane wcześniej fragmenty kodu w jedną funkcję `dot_product_attention` wyznaczającą wartości atencji opartej o iloczyn skalarny.\n",
        "*   Na wejściu funkcja otrzyma zapytania, klucze i wartości jako tensory `Q`, `K`, `V`\n",
        "*   Zwróci parę tensorów: wynikową wartość oraz wagi atencji\n",
        "\n",
        "**Uwaga**: Funkcja powinna operować zarówno na dwuwymiarowych tensorach (macierzach) `(seq_len, d)` oraz trójwymiarowych tensorach zawierających jako pierwszy wymiar wsadu `(batch_size, seq_len, d)`. Aby funkcja poprawnie działała na macierzach o trzech wymiarach, wykorzystaj metodę `transpose` do transpozycji dwóch ostatnich wymiarów tensora `K`."
      ],
      "metadata": {
        "id": "F516VcPui90J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dot_product_attention(Q: Tensor, K: Tensor, V: Tensor) -> tuple[Tensor, Tensor]:\n",
        "    d = Q.size(-1)\n",
        "    scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d, dtype=torch.float32))\n",
        "    attention_weights = F.softmax(scores, dim=-1)\n",
        "    output = torch.matmul(attention_weights, V)\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "gxiM57TZi97i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spradzenie działania funkcji dot_product_attention\n",
        "\n",
        "batch_size = 2\n",
        "seq_length = 4\n",
        "d = 6\n",
        "\n",
        "# Sprawdzenie działania dla dwuywymiarowego tensora\n",
        "X = torch.rand(seq_length, d)\n",
        "Q = torch.matmul(X, W_q)\n",
        "K = torch.matmul(X, W_k)\n",
        "V = torch.matmul(X, W_v)\n",
        "\n",
        "output, attention_weights = dot_product_attention(Q, K, V)\n",
        "print(f\"{output.shape=}\")\n",
        "print(f\"{attention_weights.shape=}\")\n",
        "\n",
        "assert output.shape == X.shape\n",
        "assert attention_weights.shape == (seq_length, seq_length)"
      ],
      "metadata": {
        "id": "9rWh2naam0eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sprawdzenie działania dla trójwymiarowego tensora\n",
        "X = torch.rand(batch_size, seq_length, d)\n",
        "Q = torch.matmul(X, W_q)\n",
        "K = torch.matmul(X, W_k)\n",
        "V = torch.matmul(X, W_v)\n",
        "\n",
        "output, attention_weights = dot_product_attention(Q, K, V)\n",
        "print(f\"{output.shape=}\")\n",
        "print(f\"{attention_weights.shape=}\")\n",
        "\n",
        "assert output.shape == X.shape\n",
        "assert attention_weights.shape == (batch_size, seq_length, seq_length)"
      ],
      "metadata": {
        "id": "IOanXKiinIj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implementacja uproszczonej architektury dwukierunkowego Transformera\n",
        "\n",
        "W dalszej części notatnika zaimplementujemy uproszczoną architekturę dwukierunkowego Transformera i zastosujemy do zadania klasyfikacji elementów wejściowej sekwencji.\n",
        "\n",
        "**Dwukierunkowy Transformer**, inaczej **tylko-koder**, wyznaczając wartość atencji dla elementu sekwencji bierze pod uwagę wszystkie elementy z sekwencji, zarówne te poprzedzające jak i następujące później. Jest stosowany w modelach językowych klasy tylko-koder, takich jak BERT.\n",
        "W odróżnieniu od pełnej architektury Transformera nasz model będzie wykorzystywał tylko jedną głowicę atencji.\n",
        "\n",
        "**Jednokierunkowy Transformer**, inaczej **tylko-dekoder**,\n",
        "wyznaczając wartość atencji dla elemetu sekwencji bierze pod uwagę tylko elementy występujące nie później w sekwencji.\n",
        "Podczas wyznaczania wartości atencji stosowana jest maska atencji przyczynowej (*causal attention mask*), która dla każdego elementu w sekwencji maskuje dostęp do elementów po nim następujących.\n",
        "Są stosowane w generatywnych modelach językowych takich, jak GPT.\n"
      ],
      "metadata": {
        "id": "LZcwSGMWDqbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Klasa `SingleHeadAttention` implementuje jednogłowicową warstwę auto-atencji bez maskowania."
      ],
      "metadata": {
        "id": "dOS_0pq3DouH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model: int):\n",
        "        super().__init__()\n",
        "\n",
        "        # Macierze projekcji zaimplementujemy jako warstwa liniowa bez wektora obciążenia (bias)\n",
        "        self.Q_w = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.K_w = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.V_w = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "    def forward(self, X: Tensor) -> tuple[Tensor, Tensor]:\n",
        "        Q = self.Q_w(X)\n",
        "        K = self.K_w(X)\n",
        "        V = self.V_w(X)\n",
        "\n",
        "        values, attention = dot_product_attention(Q, K, V)\n",
        "        return values, attention"
      ],
      "metadata": {
        "id": "oOm6-b-2crgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "att = SingleHeadAttention(d_model=d)\n",
        "\n",
        "values, attention = att(X)\n",
        "print(values.shape)\n",
        "print(attention.shape)"
      ],
      "metadata": {
        "id": "CKI5PDjVqdvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementacja pojedynczej warstwy (pojedycznego bloku) kodera Transformer."
      ],
      "metadata": {
        "id": "hUInm5VkPAu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dim_feedforward: int):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            d_model - Dimensionality of the input\n",
        "            dim_feedforward - Dimensionality of the hidden layer in the MLP\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn = SingleHeadAttention(d_model)\n",
        "\n",
        "        self.linear_net = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_feedforward),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(dim_feedforward, d_model)\n",
        "        )\n",
        "\n",
        "        # Layers to apply in between the main layers\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Attention part\n",
        "        attn_out, _ = self.self_attn(x)\n",
        "\n",
        "        # Połączenie rezydualne\n",
        "        x = x + attn_out\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # MLP part\n",
        "        linear_out = self.linear_net(x)\n",
        "        x = x + linear_out\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "HI_TpsgGQhet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = TransformerEncoderLayer(d_model=d, dim_feedforward=2*d)\n",
        "print(encoder)"
      ],
      "metadata": {
        "id": "W9wNNwKnQxyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdzenie działania warstwy kodera Transformer. Na wejściu podajemy tensor o rozmiarach `(batch_size, seq_length, d)` - złożony z `batch_size` sekwencji o `seq_length` elementach/wektorach rozmiaru `d` każdy.\n",
        "Zauważmy, że na wyjściu otrzymujemy tensor o identycznym kształcie"
      ],
      "metadata": {
        "id": "M9j4p2M2KSRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(batch_size, seq_length, d)\n",
        "print(f\"{x.shape=}\")\n",
        "\n",
        "y = encoder(x)\n",
        "print(f\"{y.shape=}\")"
      ],
      "metadata": {
        "id": "TERTpZcTJ_7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementacja zestawu `num_layers` sekwencyjnie połączonych  warstw kodera Transformer."
      ],
      "metadata": {
        "id": "dBRnQQtmJWOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, num_layers: int, d_model: int, dim_feedforward: int):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([TransformerEncoderLayer(d_model, dim_feedforward) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "        return x\n",
        "\n",
        "    def get_attention_maps(self, x):\n",
        "        attention_maps = []\n",
        "        for l in self.layers:\n",
        "            _, attn_map = l.self_attn(x)\n",
        "            attention_maps.append(attn_map)\n",
        "            x = l(x)\n",
        "        return attention_maps"
      ],
      "metadata": {
        "id": "g6FS3nsYQhja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = TransformerEncoder(num_layers=2, d_model=d, dim_feedforward=2048)\n",
        "print(encoder)"
      ],
      "metadata": {
        "id": "D5j55oGcQp1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(batch_size, seq_length, d)\n",
        "print(f\"{x.shape=}\")\n",
        "\n",
        "y = encoder(x)\n",
        "print(f\"{y.shape=}\")"
      ],
      "metadata": {
        "id": "88n_Ei9YLN4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dodatkowe elementy - kodowanie pozycyjne"
      ],
      "metadata": {
        "id": "1jCzvsvqQpvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        \"\"\"\n",
        "        Inputs\n",
        "            d_model - Hidden dimensionality of the input.\n",
        "            max_len - Maximum length of a sequence to expect.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n",
        "        # Used for tensors that need to be on the same device as the module.\n",
        "        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n",
        "        self.register_buffer('pe', pe, persistent=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x"
      ],
      "metadata": {
        "id": "F3N-E5r_Qp4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kompletna architektura uproszczonego Transformera klasy tylko-koder. Model zostanie wykorzystany do klasyfikacji każdego elementu z sekwencji wejściowej. W tym celu zdefiniujemy głowicę klasyfikacyjną (klasyfikator liniowy) `self.classification = nn.Linear(d_model, num_classes)`. Głowica klasyfikacyjna będzie estymowała rozkład prawdopodobieństwa klas dla każdego wektora w sekwencji wejściowej na podstawie ich kontekstowych reprezentacji.\n",
        "\n"
      ],
      "metadata": {
        "id": "YfYd6WPEakif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size: int, d_model: int, num_classes: int, num_layers: int):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "        self.transformer = TransformerEncoder(num_layers, d_model, 2*d_model)\n",
        "        self.classification = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.positional_encoding(x)\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        assert x.dim() == 3\n",
        "        # Jako reprezentację całej sekwencji bierzemy uśrednione wektory reprezentacji\n",
        "        # x = x.mean(dim=1)\n",
        "        x = self.classification(x)\n",
        "        return x\n",
        "\n",
        "    def get_attention_maps(self, x):\n",
        "        \"\"\"\n",
        "        Function for extracting the attention matrices of the whole Transformer for a single batch.\n",
        "        Input arguments same as the forward pass.\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            x = self.embeddings(x)\n",
        "            x = self.positional_encoding(x)\n",
        "            attention_maps = self.transformer.get_attention_maps(x)\n",
        "        return attention_maps"
      ],
      "metadata": {
        "id": "zp0UL7UZM5j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyTransformer(vocab_size=10, d_model=32, num_classes=10, num_layers=1)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "qXY7vUnMNxUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do wytrenowania modelu wykorzystamy bibliotekę PyTorch Lightning."
      ],
      "metadata": {
        "id": "Ykuxt5QVGEQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q lightning\n",
        "!pip install -q torchmetrics"
      ],
      "metadata": {
        "id": "9_zlBQaFMGtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning as L\n",
        "import torchmetrics\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class LitNet(L.LightningModule):\n",
        "    def __init__(self, classifier: nn.Module):\n",
        "        super().__init__()\n",
        "        self.classifier = classifier\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # TODO: Change hard coded number of classes\n",
        "        self.metric_train_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "        self.metric_val_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "        self.metric_test_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # training_step implementuje jeden krok pętli treningowej\n",
        "        x, target = batch\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        logits = logits.view(-1, logits.shape[-1])\n",
        "        target = target.view(-1)\n",
        "\n",
        "        loss = self.criterion(logits, target)\n",
        "        self.log(\"train/loss\", loss, prog_bar=True)\n",
        "\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        self.metric_train_acc(preds, target)\n",
        "        self.log('train/accuracy', self.metric_train_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, target = batch\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        logits = logits.view(-1, logits.shape[-1])\n",
        "        target = target.view(-1)\n",
        "\n",
        "        loss = self.criterion(logits, target)\n",
        "        self.log(\"val/loss\", loss, prog_bar=True)\n",
        "\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        self.metric_val_acc(preds, target)\n",
        "        self.log('val/accuracy', self.metric_val_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, target = batch\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        logits = logits.view(-1, logits.shape[-1])\n",
        "        target = target.view(-1)\n",
        "\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        self.metric_test_acc(preds, target)\n",
        "        self.log('test/accuracy', self.metric_test_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.classifier.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "        lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, total_steps=self.trainer.estimated_stepping_batches)\n",
        "        return [optimizer], [{'scheduler': lr_scheduler, 'interval': 'step'}]\n"
      ],
      "metadata": {
        "id": "5NuXSnPKLzM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definicja hiper-parametrów procesu uczenia.\n",
        "\n"
      ],
      "metadata": {
        "id": "YBiH0DiyR3F1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10\n",
        "d_model = 32\n",
        "num_classes = vocab_size\n",
        "num_layers = 1"
      ],
      "metadata": {
        "id": "VNSjjezFSDZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init the network\n",
        "my_transformer = MyTransformer(vocab_size=vocab_size, d_model=d_model, num_classes=num_classes, num_layers=num_layers)\n",
        "# Wrap in a lightning module\n",
        "lit_model = LitNet(my_transformer)"
      ],
      "metadata": {
        "id": "Pqd5AzutU8K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Zadanie: Odwrócenie kolejności elementów w sekwencji"
      ],
      "metadata": {
        "id": "TWeL3hInTSwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Zbiór danych\n",
        "Wygenerujemy syntetyczny zbiór danych zawierający sekwencje liczb od 0 do 9.\n",
        "Naszym **zadaniem będzie odwrócenie kolejności liczb w sekwencji wejściowej**.\n",
        "Potraktujemy to jako problem klasyfikacji każdego elementu sekwencji - chcemy aby model każdemu elementowi sekwencji wejściowej przypisał klasę oczekiwanego na wyjściu elementu.\n",
        "Na przykład, kolejne elementy sekwencji $1,7,3,4,2$ powinny zostać sklasyfikowane jako odpowiednio $2,4,3,7,1$ - dzięki czemu uzyskamy odwróconą sekwencję."
      ],
      "metadata": {
        "id": "6BHQw8z9HkWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class ReverseDataset(Dataset):\n",
        "\n",
        "    def __init__(self, num_categories, seq_len, size):\n",
        "        super().__init__()\n",
        "        self.num_categories = num_categories\n",
        "        self.seq_len = seq_len\n",
        "        self.size = size\n",
        "\n",
        "        self.data = torch.randint(self.num_categories, size=(self.size, self.seq_len))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inp_data = self.data[idx]\n",
        "        labels = torch.flip(inp_data, dims=(0,))\n",
        "        return inp_data, labels"
      ],
      "metadata": {
        "id": "rWqD69gUPlMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(ReverseDataset(num_categories=10, seq_len=8, size=50000), batch_size=128, shuffle=True, drop_last=True, pin_memory=True)\n",
        "val_loader   = DataLoader(ReverseDataset(num_categories=10, seq_len=8, size=1000), batch_size=128)\n",
        "test_loader  = DataLoader(ReverseDataset(num_categories=10, seq_len=8, size=10000), batch_size=128)"
      ],
      "metadata": {
        "id": "lYtpswQkVcJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Przykładowa sekwencja wejściowa i etykiety określające oczekiwane wyjście - klasy które powinny zostać przypisane przez model każdemu elementowi sekwencji wejściowej."
      ],
      "metadata": {
        "id": "8SwdGd1KJeD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp_data, labels = train_loader.dataset[0]\n",
        "print(\"Wejście:  \", inp_data)\n",
        "print(\"Etykiety: \", labels)"
      ],
      "metadata": {
        "id": "Kwe08Q3bVcMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "inputs, targets = batch\n",
        "\n",
        "print(inputs.shape)\n",
        "print(targets.shape)\n",
        "\n",
        "y = my_transformer(inputs)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "kY5o76TkQRUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdzenie działania modelu z losowo zainicjalizowanymi wagami."
      ],
      "metadata": {
        "id": "46EumsHDL04k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x, target, predicted in zip(inputs[0], targets[0], y[0]):\n",
        "    print(f\"Element z wejściowej sekwencji : {x}   Etykieta: {target}   Predykowana klasa: {predicted.detach().argmax(dim=0)}\")"
      ],
      "metadata": {
        "id": "embdLXnKK5u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modele sieci neuronowych inicjalizowane są z losowymi wagami. PyTorch domyślnie inicjalizuje wagi model korzystając z metody Xaviera lub He. Więcej informacji: [link](https://www.deeplearning.ai/ai-notes/initialization/index.html).\n",
        "\n",
        "Sprawdzimy maskę wag atencji wyznaczoną przez niewytrenowany model. Nie widać specjalnych zależności. Dla każdego elementu w sekwencji (wiersza) wagi atencji względem pozostałych elementów (kolumny) wyglądają losowo."
      ],
      "metadata": {
        "id": "L2K43bayPKDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "data_input, labels = next(iter(val_loader))\n",
        "data_input = data_input.to(device)\n",
        "attention_maps = my_transformer.get_attention_maps(data_input)"
      ],
      "metadata": {
        "id": "7CqyYI6hRnHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_attention_map(attention_weights):\n",
        "    # Wizualizacja pojedycznej mapy atencji\n",
        "    assert attention_weights.dim() == 2\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(attention_weights.detach().cpu().numpy(), cmap=\"Blues\")\n",
        "    plt.xlabel(\"Keys\")\n",
        "    plt.ylabel(\"Queries\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "htROdB2exekL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wizualizacja mapy atencji z pierwszej warstwy kodera Transformer dla pierwszej sekwencji ze wsadu\n",
        "visualize_attention_map(attention_maps[0][0])"
      ],
      "metadata": {
        "id": "_A5X9C-JPCBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Trenowanie modelu\n",
        "Rozpoczęcie treningu modelu."
      ],
      "metadata": {
        "id": "pBQqOJxSKZ9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = \"saved_models/\"\n",
        "\n",
        "max_epochs = 3\n",
        "lr = 5e-4\n",
        "warmup = 50\n",
        "max_iters = max_epochs*len(train_loader)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=2, log_every_n_steps=50)\n",
        "trainer.fit(\n",
        "    lit_model,\n",
        "    train_dataloaders=train_loader,\n",
        "    val_dataloaders=val_loader\n",
        "    )"
      ],
      "metadata": {
        "id": "KZhbPTygWD3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ewaluacja modelu\n",
        "Ewaluacja wytrenowanego modelu na zbiorze testowym."
      ],
      "metadata": {
        "id": "Dk5g7-oNKnvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(dataloaders=test_loader)"
      ],
      "metadata": {
        "id": "eevqpQtPZrfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdźmy wynik działania wytrenowanego modelu dla przykładowego wejścia."
      ],
      "metadata": {
        "id": "g-YL80AXKyJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(test_loader))\n",
        "inputs, targets = batch\n",
        "\n",
        "print(inputs.shape)\n",
        "print(targets.shape)\n",
        "\n",
        "y = my_transformer(inputs)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "A0eS_AzYMV-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, target, predicted in zip(inputs[0], targets[0], y[0]):\n",
        "    print(f\"Element z wejściowej sekwencji : {x}   Etykieta: {target}   Predykowana klasa: {predicted.detach().argmax(dim=0)}\")"
      ],
      "metadata": {
        "id": "6TYbwyZsKxwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wizualizacja mapy atencji dla przykładowego wejścia. Dla $i$-tego elementu w sekwencji model nauczył się zwracać uwagę na $i$-ty od końca element.\n",
        "I o to chodziło, wyznaczając wartość $i$-tego elementu w odwróconej sekwencji należy wziąć wartość $i$-tego od końca elementu w wejściowej sekwencji."
      ],
      "metadata": {
        "id": "jroGFGAeSrfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_maps = my_transformer.get_attention_maps(data_input)\n",
        "# Odwołanie do map atencji z pierwszej warstwy dla pierwszej sekwencji ze wsadu\n",
        "visualize_attention_map(attention_maps[0][0])"
      ],
      "metadata": {
        "id": "yvtfXCO-xvFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zauważmy, że model nauczył się przekształcać sekwencje liczb poprzez demonstrację par złożonych z przykładowych sekwencji wejściowych i oczekiwanego wejścia."
      ],
      "metadata": {
        "id": "BBUeqFlFTb0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Zadanie: Zbalansowane nawiasy"
      ],
      "metadata": {
        "id": "H9fm2FksNL9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem odwrócenia kolejności ciągu był bardzo prosty. Model nie musiał brać pod uwagę wartości elementów w sekwencji - wystarczyło, że nauczył się aby jako wartość $i$-tego elementu wyjścia brać $n-i$-ty element wejścia.\n",
        "\n",
        "Spróbujmy trudniejszego problemu - sprawdzenia czy sekwencja nawiasów jest zbalansowana. Rozwiązanie tego problemy wymaga wzięcia pod uwagę zarówno pozycji elementów (nawiasów) jak i ich wartości (otwierający czy zamykający).\n",
        "\n",
        "W odróżnieniu od poprzedniego problemu klasyfikujemy całą sekwencję - czy zawiera zrównoważone nawiasy czy nie. Czyli klasyfikator musimy oprzeć na wektorze reprezentującym całą sekwencję, a nie pojedyczy element.\n",
        "Aby uzyskać **reprezentację o stałej długości dla całej sekwencji** można zastosować następujące podejścia:\n",
        "- Na początku sekwencji dodać specjalny token `CLS` i kontekstową reprezentację tego tokenu traktować jak reprezentację całej sekwencji wejściowej. To podejście jest typowo stosowane w modelach klasy tylko-koder, np. BERT.\n",
        "- Uśrednić kontekstowe reprezentacje wszystkich tokenów w sekwencji. W dalszej części notatnika zastosujemy to podejście."
      ],
      "metadata": {
        "id": "bky7syB8VkJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Zbiór danych"
      ],
      "metadata": {
        "id": "wyWT3HjgTbwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pomocnicze funkcje tworzące zbiór danych złożony z napisów ze zbalansowanymi i nie zbalansowanymi nawiasami."
      ],
      "metadata": {
        "id": "vmafFXYITmoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_balanced_brackets(n: int) -> list[str]:\n",
        "    \"\"\"Generate all balanced brackets string with n pairs.\"\"\"\n",
        "    result = []\n",
        "\n",
        "    def backtrack(current, open_count, close_count):\n",
        "        if len(current) == 2 * n:\n",
        "            result.append(current)\n",
        "            return\n",
        "\n",
        "        if open_count < n:\n",
        "            backtrack(current + \"(\", open_count + 1, close_count)\n",
        "        if close_count < open_count:\n",
        "            backtrack(current + \")\", open_count, close_count + 1)\n",
        "\n",
        "    backtrack(\"\", 0, 0)\n",
        "    return result"
      ],
      "metadata": {
        "id": "QN3NwlX6Tpxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_brackets(length) -> str:\n",
        "    \"\"\"Generate a random string of open or close brackets.\"\"\"\n",
        "    return \"\".join(random.choice([\"(\", \")\"]) for _ in range(length))"
      ],
      "metadata": {
        "id": "3jz3t5vIT8kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_balanced(s: str) -> bool:\n",
        "    \"\"\"Check if a string of brackets is balanced.\"\"\"\n",
        "    balance = 0\n",
        "    for char in s:\n",
        "        if char == \"(\":\n",
        "            balance += 1\n",
        "        elif char == \")\":\n",
        "            balance -= 1\n",
        "        if balance < 0:\n",
        "            return False\n",
        "    return balance == 0"
      ],
      "metadata": {
        "id": "cENxaAgOT_XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BracketDataset(Dataset):\n",
        "\n",
        "    def __init__(self, num_pairs: int):\n",
        "        super().__init__()\n",
        "        self.num_pairs = num_pairs\n",
        "        self.balanced_brackets = generate_balanced_brackets(num_pairs)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.balanced_brackets) * 2\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx % 2 == 0:\n",
        "            s = self.balanced_brackets[idx // 2]\n",
        "            label = 1\n",
        "        else:\n",
        "            s = generate_random_brackets(self.num_pairs*2)\n",
        "            label = 0\n",
        "\n",
        "        # Kodowanie: 0=\"(\", 1=\")\"\n",
        "        x = torch.tensor([0 if ch==\"(\" else 1 for ch in s])\n",
        "        label = torch.tensor(label)\n",
        "        return x, label"
      ],
      "metadata": {
        "id": "ajhm1O5nWlTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Przykładowe elementy ze zbioru danych - `0` oznacza nawias otwierający a `1` nawias zamykający. Etykieta `1` oznacza, że sekwencja nawiasów jest zbalansowana, a `0` przeciwnie."
      ],
      "metadata": {
        "id": "LshoAS0NPJBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = BracketDataset(num_pairs=10)\n",
        "print(len(ds))\n",
        "print(ds[0])\n",
        "print(ds[1])\n",
        "print(ds[2])\n",
        "print(ds[3])\n",
        "print(ds[4])"
      ],
      "metadata": {
        "id": "WTo9XyG2hRe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_dataset_element(e):\n",
        "    # Zdekoduj elementy zbioru danych\n",
        "    x, label = e\n",
        "    s = \"\".join([\"(\" if ch==0 else \")\" for ch in x])\n",
        "    s = f'{s}   {\"balanced\" if label==1 else \"unbalanced\"}'\n",
        "    return s"
      ],
      "metadata": {
        "id": "SbRdyZX1SFWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode_dataset_element(ds[0]))\n",
        "print(decode_dataset_element(ds[1]))\n",
        "print(decode_dataset_element(ds[2]))\n",
        "print(decode_dataset_element(ds[3]))"
      ],
      "metadata": {
        "id": "A07Bm1u1SKgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_size = int(0.8 * len(ds))\n",
        "val_size = int(0.1 * len(ds))\n",
        "test_size = len(ds) - train_size - val_size\n",
        "\n",
        "train_ds, val_ds, test_ds = random_split(ds, [train_size, val_size, test_size])\n",
        "\n",
        "print(f\"Rozmiar zbioru trningowego: {len(train_ds)}\")\n",
        "print(f\"Rozmiar zbioru walidacyjnego: {len(val_ds)}\")\n",
        "print(f\"Rozmiar zbioru testowego: {len(test_ds)}\")"
      ],
      "metadata": {
        "id": "1q8JkomGicG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=128)\n",
        "test_loader  = DataLoader(test_ds, batch_size=128)"
      ],
      "metadata": {
        "id": "EiUhC72micKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Definicja architektury modelu"
      ],
      "metadata": {
        "id": "R_j5z4IITxSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definicja modelu o architekturze Transformer klasy tylko-koder z liniową głowicą klasyfikującą sekwencję. Głowica klasyfikacyjna `self.classification` oparta jest o uśrednione kontekstowe reprezentacje elementów w sekwencji."
      ],
      "metadata": {
        "id": "gvDw_2sRPiJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size: int, d_model: int, num_classes: int, num_layers: int):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "        self.transformer = TransformerEncoder(num_layers, d_model, 2*d_model)\n",
        "        self.classification = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.positional_encoding(x)\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        assert x.dim() == 3\n",
        "\n",
        "        # Jako reprezentację całej sekwencji bierzemy uśrednione wektory reprezentacji\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.classification(x)\n",
        "        return x\n",
        "\n",
        "    def get_attention_maps(self, x):\n",
        "        \"\"\"\n",
        "        Function for extracting the attention matrices of the whole Transformer for a single batch.\n",
        "        Input arguments same as the forward pass.\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            x = self.embeddings(x)\n",
        "            x = self.positional_encoding(x)\n",
        "            attention_maps = self.transformer.get_attention_maps(x)\n",
        "        return attention_maps"
      ],
      "metadata": {
        "id": "xgEJZ_KBjx1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LitNet(L.LightningModule):\n",
        "    def __init__(self, classifier: nn.Module):\n",
        "        super().__init__()\n",
        "        self.classifier = classifier\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # TODO: Change hard coded number of classes\n",
        "        self.metric_train_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=2)\n",
        "        self.metric_val_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=2)\n",
        "        self.metric_test_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=2)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # training_step implementuje jeden krok pętli treningowej\n",
        "        x, target = batch\n",
        "        logits = self.classifier(x)\n",
        "        loss = self.criterion(logits, target)\n",
        "        self.log(\"train/loss\", loss, prog_bar=True)\n",
        "\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        self.metric_train_acc(preds, target)\n",
        "        self.log('train/accuracy', self.metric_train_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, target = batch\n",
        "        logits = self.classifier(x)\n",
        "        loss = self.criterion(logits, target)\n",
        "        self.log(\"val/loss\", loss, prog_bar=True)\n",
        "\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        self.metric_val_acc(preds, target)\n",
        "        self.log('val/accuracy', self.metric_val_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, target = batch\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        self.metric_test_acc(preds, target)\n",
        "        self.log('test/accuracy', self.metric_test_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.classifier.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "        lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, total_steps=self.trainer.estimated_stepping_batches)\n",
        "        return [optimizer], [{'scheduler': lr_scheduler, 'interval': 'step'}]"
      ],
      "metadata": {
        "id": "j_zTOO65icPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utworzenie instancji modelu sieci MyTransformer złożonej z jednej warstwy kodera Transformer (`num_layers=1`)."
      ],
      "metadata": {
        "id": "LsxVjYE9QGAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init the network\n",
        "my_transformer = MyTransformer(vocab_size=2, d_model=32, num_classes=2, num_layers=1)\n",
        "# Wrap in a lightning module\n",
        "lit_model = LitNet(my_transformer)"
      ],
      "metadata": {
        "id": "v5lNLAr4kKeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Trenowanie modelu"
      ],
      "metadata": {
        "id": "JutVVw3LT2Y8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uruchom trenowanie modelu."
      ],
      "metadata": {
        "id": "LXFIVPWFP9F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = \"saved_models/\"\n",
        "\n",
        "max_epochs = 6\n",
        "lr = 5e-4\n",
        "warmup = 50\n",
        "max_iters = max_epochs*len(train_loader)\n",
        "\n",
        "#trainer = L.Trainer(max_epochs=num_epochs, logger=wandb_logger)\n",
        "trainer = L.Trainer(max_epochs=2, log_every_n_steps=50)\n",
        "trainer.fit(\n",
        "    lit_model,\n",
        "    train_dataloaders=train_loader,\n",
        "    val_dataloaders=val_loader\n",
        "    )"
      ],
      "metadata": {
        "id": "mGq8X_A1kV_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ewaluacja modelu"
      ],
      "metadata": {
        "id": "GL4Et0mkT6BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(dataloaders=test_loader)"
      ],
      "metadata": {
        "id": "BBJZ_3EgkWCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skuteczność klasyfikacji jest ograniczona (dokładność rzędu 93%), wytrenowany model nie jest w stanie poprawnie sprawdzić zbalansowania nawiasów dla każdej sekwencji wejściowej.\n",
        "\n",
        "Wizualizacja mapy atencji dla przykładowego wejścia."
      ],
      "metadata": {
        "id": "JQ-3abB1QtXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "data_input, labels = next(iter(val_loader))\n",
        "data_input = data_input.to(device)\n",
        "attention_maps = my_transformer.get_attention_maps(data_input)\n",
        "\n",
        "# Odwołanie do map atencji z dla pierwszej sekwencji ze wsadu\n",
        "visualize_attention_map(attention_maps[0][0])\n",
        "print(data_input[1])"
      ],
      "metadata": {
        "id": "_NyT7pUykWE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdzimy czy większy model, złożony z trzech warstw kodera Transformer (`num_layers=3`) pozwoli osiągnąć lepsze wyniki."
      ],
      "metadata": {
        "id": "kECM2jTHQUUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init the network\n",
        "my_transformer = MyTransformer(vocab_size=2, d_model=32, num_classes=2, num_layers=3)\n",
        "# Wrap in a lightning module\n",
        "lit_model = LitNet(my_transformer)"
      ],
      "metadata": {
        "id": "52neC4FEQUbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = \"saved_models/\"\n",
        "\n",
        "max_epochs = 6\n",
        "lr = 5e-4\n",
        "warmup = 50\n",
        "max_iters = max_epochs*len(train_loader)\n",
        "\n",
        "#trainer = L.Trainer(max_epochs=num_epochs, logger=wandb_logger)\n",
        "trainer = L.Trainer(max_epochs=2, log_every_n_steps=50)\n",
        "trainer.fit(\n",
        "    lit_model,\n",
        "    train_dataloaders=train_loader,\n",
        "    val_dataloaders=val_loader\n",
        "    )"
      ],
      "metadata": {
        "id": "cbF9lM3pkWHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(dataloaders=test_loader)"
      ],
      "metadata": {
        "id": "GkUOcdc3QWyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zwiększenie liczy warstw kodera do trzech pozwoliło lepiej uchwycić zależności między elementami sekwencji. Skuteczność klasyfikacji na zbiorze testowym wzrosła z 93 do 97%."
      ],
      "metadata": {
        "id": "Mqcc2lWFRN7o"
      }
    }
  ]
}