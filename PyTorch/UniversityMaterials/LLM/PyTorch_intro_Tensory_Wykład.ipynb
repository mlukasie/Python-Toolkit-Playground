{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY88NuVprDxy"
      },
      "source": [
        "#PyTorch Intro - Tensory - Wykład\n",
        "\n",
        "**Tensor** w bibliotece PyTorch jest specjalizowaną strukturą danych podobną do wielowymiarowej tablicy `ndarray` w bibliotece numpy. Na tensorach można wykonywać typowe operacje algebry liniowej oraz operacje specyficzne dla głębokiego uczenia jak na przykład automatyczne różniczkowanie (autograd).\n",
        "Tensory wykorzystujemy do przechowywania przetwarzanych danych oraz parametrów (wag) modeli. Biblioteka PyTorch pozwala na efektywne przetwarzanie tensorów na CPU lub GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ6auP2WCnLW"
      },
      "source": [
        "##Przygotowanie środowiska\n",
        "Upewnij się, że notatnik jest uruchomiony na maszynie z GPU. Jeśli GPU nie jest dostępne zmień typ maszyny (Runtime | Change runtime type) i wybierz T4 GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfwBYOmmnw0b"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1G8i4wTrfq6"
      },
      "source": [
        "Biblioteka PyTorch (`torch`) jest domyślnie zainstalowana w środowisku COLAB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDGaiuGLrapP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "print(f\"Wersja biblioteki PyTorch: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ6c3h4nryQJ"
      },
      "source": [
        "Sprawdzenie dostępnego urządzenia GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGyMG3_2rxIC"
      },
      "outputs": [],
      "source": [
        "print(f\"Dostępność GPU: {torch.cuda.is_available()}\")\n",
        "print(f\"Typ GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cazrrG01sbUH"
      },
      "source": [
        "##Tworzenie tensorów"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYHxgRXovNuk"
      },
      "source": [
        "Funkcja `tensor()` ([link](https://pytorch.org/docs/stable/generated/torch.tensor.html#torch-tensor)) **konstruuje tensor z podanych danych** na domyślnym urządzeniu (CPU jeśli nie podano inaczej). Typ utworzonego tensora, o ile nie podamy inaczej, odpowiada typowi danych źródłowych. W tym przypadku utworzony został tensor przechowujący dane typu `torch.float32` (32-bitowa liczba zmiennoprzecinkowa)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P0IOmiovOG3"
      },
      "outputs": [],
      "source": [
        "data = [[1.1, 2.1, 3.5],[4.2, 5.7, 0.6],[3.2, 0.7, 1.7]]\n",
        "\n",
        "x = torch.tensor(data)\n",
        "print(f\"{x=}\")\n",
        "print(f\"{type(x)=}\")\n",
        "print(f\"{x.dtype=}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEpqD_XU3hNC"
      },
      "source": [
        "**Wybrane atrybuty i metody tensorów**:\n",
        "*   `dtype` - typ tensora (lista dostępnych typów: [link](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype))\n",
        "*   `device` - urządzenie na którym jest przechowywany i będzie przetwarzany tensor ([link](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device))\n",
        "*   `layout` - format pamięci w jakim przechowywana jest zawartość tensora ([link](https://pytorch.org/docs/stable/tensor_attributes.html#torch.layout))\n",
        "*   `shape` - rozmiar każdego wymiaru tensora (to samo co metoda `size()`)\n",
        "*   `ndim` - liczba wymiarów tensora\n",
        "*   `numel()` - liczba elementów tensora\n",
        "*   `size()` - rozmiar każdego wymiaru tensora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prqGNGG03iyz"
      },
      "outputs": [],
      "source": [
        "print(f\"{x.dtype=}\")\n",
        "print(f\"{x.device=}\")\n",
        "print(f\"{x.layout=}\")\n",
        "print(f\"{x.ndim=}\")\n",
        "print(f\"{x.numel()=}\")\n",
        "print(f\"{x.shape=}\")\n",
        "print(f\"{x.size()=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeCD_5gswMQh"
      },
      "source": [
        "Funkcja `torch.from_numpy(ndarray)` **tworzy tensor z tablicy `ndarray` z biblioteki numpy**. Uwaga: Tak utworzony tensor korzysta z tego samego obszaru pamięci co źródłowa tablica `ndarray`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1zL56T0wMXN"
      },
      "outputs": [],
      "source": [
        "array = np.array([[1, 7, 3], [2, 5, 11]])\n",
        "print(array)\n",
        "x = torch.from_numpy(array)\n",
        "print(f\"{x=}\")\n",
        "print(f\"{type(x)=}\")\n",
        "print(f\"{x.dtype=}\")\n",
        "print(f\"{x.device=}\")\n",
        "print(f\"{x.shape=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2n4iMe0x4Kv"
      },
      "source": [
        "Przydatne funkcje tworzące zainicjalizowane tensory:\n",
        "*   `torch.zeros(size, ...)` - tensor wypełniony zerami\n",
        "*   `torch.ones(size, ...)` - tensor wypełniony jedynkami\n",
        "*   `torch.full(size, fill_value, ...)` - tensor wypełniony podaną wartością\n",
        "*   `torch.rand(size, ...)` - tensor o wartościach losowych o rozkładzie jednostajnym z przedziału $[0,1)$\n",
        "*   `torch.randn(size, ...)` - tensor o wartościach losowych o standardowym rozkładzie normalnym\n",
        "*   `torch.randint(low, high, size, ...)` - tensor losowych liczb całkowitych z przedziału `[low, high)`\n",
        "*   `torch.arange(start=0, end, step=1, ...)` - jednowymiarowy tensor (wektor) o wartościach z przedziału `[start, end)` z krokiem  `step`\n",
        "\n",
        "Opcjonalne parametry `dtype` i `device` pozwalają określić typ danych i urządzenie na którym przechowywany będzie tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKIwt6eH7kcu"
      },
      "outputs": [],
      "source": [
        "size = (2, 3)\n",
        "\n",
        "zeros_tensor = torch.zeros(size)\n",
        "ones_tensor = torch.ones(size, device = \"cuda\", dtype=torch.int64)\n",
        "full_tensor = torch.full(size, 3.14)\n",
        "rand_tensor = torch.rand(size, device = \"cuda\")\n",
        "randn_tensor = torch.rand(size)\n",
        "randint_tensor = torch.randint(0, 100, size)\n",
        "x = torch.arange(2, 10)\n",
        "\n",
        "print(f\"Tensor zer: \\n {zeros_tensor} \\n\")\n",
        "print(f\"Tensor jedynek: \\n {ones_tensor} \\n\")\n",
        "print(f\"Tensor losowy (rozkład równomierny na [0,1)): \\n {rand_tensor} \\n\")\n",
        "print(f\"Tensor losowy (standardowy rozkład normalny): \\n {randn_tensor} \\n\")\n",
        "print(f\"Tensor losowy (liczby całkowite): \\n {randint_tensor} \\n\")\n",
        "print(f\"torch.arange: \\n {x} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDi3-uoCzsoe"
      },
      "source": [
        "Funkcje z rozszerzeniem `_like` (`torch.zeros_like`, `torch.ones_like`, `torch.full_like`, `torch.rand_like`, ...) domyślnie tworzą tensory o identycznych własnościach (rozmiary, typ danych, urządzenie, ...) jak tensory podane jako argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D-NUVTf5j0l"
      },
      "outputs": [],
      "source": [
        "x_source = torch.rand(2, 4, device=\"cuda\")\n",
        "print(x_source)\n",
        "print()\n",
        "x_ones = torch.ones_like(x_source)\n",
        "print(x_ones)\n",
        "print()\n",
        "x_zeros = torch.zeros_like(x_source)\n",
        "print(x_zeros)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6xYBYbCAuMI"
      },
      "source": [
        "##Operacje na tensorach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL2sezH40jFv"
      },
      "source": [
        "### Zmiana typu lub urządzenia\n",
        "\n",
        "Metoda `to` pozwala zmienić typ tensora lub urządzenie na którym będzie przetwarzany tensor. Metoda `cpu` przesyła tensor na CPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMs6YZ2J0eUZ"
      },
      "outputs": [],
      "source": [
        "x = torch.randint(0, 100, (3, 2))\n",
        "print(x)\n",
        "print(f\"{x.dtype=}   {x.device=}\\n\")\n",
        "\n",
        "cuda_device = torch.device('cuda:0')\n",
        "y = x.to(cuda_device)\n",
        "print(y)\n",
        "print(f\"{y.dtype=}   {y.device=}\\n\")\n",
        "\n",
        "y = y.to(torch.float32)\n",
        "print(y)\n",
        "print(f\"{y.dtype=}   {y.device=}\\n\")\n",
        "\n",
        "z = y.to('cpu')\n",
        "print(f\"{z.dtype=}   {z.device=}\\n\")\n",
        "\n",
        "z = y.cpu()\n",
        "print(f\"{z.dtype=}   {z.device=}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFsSEF_8CzgH"
      },
      "source": [
        "###Indeksowanie tensorów\n",
        "\n",
        "Biblioteka PyTorch posiada podobny **mechanizm indeksowania tensorów** jak w bibliotece numpy.\n",
        "Indeksy elementów tensora wzdłuż każdej osi rozpoczynają się od `0`.\n",
        "\n",
        "Indeksy ujemne pozwalają odwołać się do elementu liczonego od końca (`x[-1]` oznacza ostatni element wektora `x`, `x[-2]` element przedostatni).\n",
        "\n",
        "Podobnie jak w bibliotece numpy wspierane jest indeksowanie przez podanie zakresu (*slicing*).\n",
        "`x[start:stop]` oznacza zakres od indeksu `start` do indeksu `stop` ale BEZ elementu o indeksie `stop`. Np. x[2:4] uwzględnia tylko elementy o indeksach 2 i 3.\n",
        "`x[start:]` oznacza elementy wektora `x` od indeksu `start` do końca.\n",
        "`x[:stop]` oznacza początkowe elementy wektora x do indeksu `stop` (ale BEZ elementu o indeksie `stop`).\n",
        "Sam dwukropek oznacza wszystkie elementy w danym wymiarze, np. `x[:, 2:5]` odwołuje się do wszystkich wierszy i kolumn 2, 3 i 4 tensora `x`.\n",
        "\n",
        "Przeczytaj opis indeksowania w bibliotece numpy: [link](https://numpy.org/doc/stable/user/basics.indexing.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvJBTLwJCznA"
      },
      "outputs": [],
      "source": [
        "x = torch.randint(0, 100, (4, 4))\n",
        "print(f\"{x=}\")\n",
        "print()\n",
        "\n",
        "x[:,1] = 0\n",
        "print(f\"{x=}\")\n",
        "print()\n",
        "\n",
        "print(f\"{x[..., 3]=}\")\n",
        "print()\n",
        "\n",
        "print(f\"{x[1:3, 2:4]=}\")\n",
        "print()\n",
        "\n",
        "print(f\"{x[-1]=}\")\n",
        "print()\n",
        "print(f\"{x[-2]=}\")\n",
        "print()\n",
        "\n",
        "print(f\"{x[:, -1]=}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rozgłaszanie (*broadcasting*)\n",
        "\n",
        "Biblioteka PyTorch wspiera **rozgłaszanie (brodcasting)**, czyli dostosowywanie wymiarów tensorów, podobnie jak w bibliotece numpy.\n",
        "Rozgłaszanie pozwala pod pewnymi warunkami wykonać operacje na tensorach o niezgodnych wymiarach.\n",
        "\n",
        "**Zasady uzgadniania rozmiarów tensorów**:\n",
        "*   Jeśli jeden z tensorów ma mniejszą liczbę wymiarów niż drugi, jest niejawnie rozszerzany poprzez dodanie jednostkowych wymiarów z przodu\n",
        "*   Jeśli dwa tensory mają różny rozmiar któregoś z wymiarów:\n",
        "    *   Jeśli jeden z nich ma rozmiar jeden, to jest niejawnie rozszerzany poprzez powielenie wartości wzdłuż tej osi\n",
        "    *   Jeśli żaden z nich nie ma rozmiaru jeden – uzgodnienie wymiarów kończy się niepowodzeniem\n",
        "\n",
        "Przeczytaj opis rozgłaszania w bibliotece numpy: [link](https://numpy.org/doc/stable/user/basics.broadcasting.html).\n",
        "\n",
        "W poniższym przykładzie tensory `x` i `y` mają niezgodne rozmiary (odpowiednio $3 \\times 1$ i $1 \\times 2$). Przed wykonaniem dodawania mechanizm rozgłaszania sprowadza je do zgodnych rozmiarów ($3 \\times 2$) poprzez powielenie jednostkowych wymiarów."
      ],
      "metadata": {
        "id": "TV0wH7wL3eyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(3).reshape((3, 1))\n",
        "y = torch.arange(10,12).reshape((1, 2))\n",
        "print(f\"{x=}\")\n",
        "print(f\"{y=}\")\n",
        "print()\n",
        "\n",
        "print(f\"{x + y=}\")"
      ],
      "metadata": {
        "id": "oQtMhL8o6yQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(4, 2).normal_(2)\n",
        "print(f\"{x=}\")\n",
        "y = x.mean(dim=0)\n",
        "print(f\"{y=}\")\n",
        "\n",
        "print(f\"{x - y=}\")"
      ],
      "metadata": {
        "id": "hqENVLvqSGHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zwróć uwagę na wynik dodawania w tym przykładzie.\n",
        "W pierwszym kroku tensor `y` o mniejszej liczbie wymiarów zostanie niejawnie rozszerzony do rozmiaru $(1,4)$ poprzez dodanie jednostkowego wymiaru z przodu."
      ],
      "metadata": {
        "id": "sPGqhuvj28vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(4).reshape((4, 1))\n",
        "y = torch.arange(4).reshape((4))\n",
        "print(f\"{x=}\")\n",
        "print(f\"{y=}\")\n",
        "print()\n",
        "\n",
        "print(f\"{x + y=}\")"
      ],
      "metadata": {
        "id": "o_ATaoOgQeI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vqA1F2dziA9"
      },
      "source": [
        "###Przekształcanie tensorów\n",
        "\n",
        "Przydatne operacje przekształcające i zmieniające rozmiary tensora:\n",
        "\n",
        "*   `squeeze` - usunięcie wybranego wymiaru rozmiaru 1\n",
        "*   `unsqueeze` - dodanie wymiaru rozmiaru 1 na wybranej pozycji\n",
        "*   `permute` - permutacja kolejności wymiarów\n",
        "*   `reshape` - zmiana kształtu (rozmiaru wymiarów) tensora; wynikowy tensor musi zawierać tyle samo elementów co wejściowy tensor\n",
        "*   `view`- podobnie jak `reshape`, ale zwraca widok wejściowego tensora\n",
        "*   `contiguous` - zwraca tensor identyczny z wejściowym, ale zajmujący ciągły obszar pamięci\n",
        "\n",
        "\n",
        "Powyższe operacje można wywoływać jako funkcje biblioteki torch (np. `torch.squeeze(x, dim=1)`, albo jako metody klasy `torch.Tensor` (np. `x.squeeze(dim=1)`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVLMyW6k2eNp"
      },
      "outputs": [],
      "source": [
        "x = torch.randn((10, 1, 5,2))\n",
        "print(f\"{x.shape=}\")\n",
        "\n",
        "x = x.squeeze(dim=1)\n",
        "print(f\"Po wykonaniu x.squeeze(dim=1) {x.shape=}\")\n",
        "\n",
        "x = x.unsqueeze(dim=0)\n",
        "print(f\"Po wykonaniu x.unsqueeze(dim=0) {x.shape=} \\n\")\n",
        "\n",
        "print(f\"{x.is_contiguous()=}\")\n",
        "x = x.permute(0, 3, 1, 2)\n",
        "print(f\"Po wykonaniu x.permute(0, 3, 1, 2) {x.shape=}\")\n",
        "print(f\"{x.is_contiguous()=}\")\n",
        "x = x.contiguous()\n",
        "print(f\"Po wykonaniu x.contiguous() {x.is_contiguous()=}\")\n",
        "\n",
        "x = x.reshape((50, 2))\n",
        "print(f\"Po wykonaniu x.reshape((50, 2)) {x.shape=}\")\n",
        "\n",
        "# Nieprawidłowa operacja\n",
        "# Wynikowy tensor musi zawierać tyle samo elementów co wejściowy tensor\n",
        "x = x.reshape((50, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wL4QSi_DrnZ"
      },
      "source": [
        "Funkcja `torch.cat` umożliwia konkatenację tensorów wzdłuż podanego wymiaru.\n",
        "Inną funkcją umożliwiającą scalanie wielu tensorów jest `torch.stack`. W odróżnieniu od `torch.cat` łączy listę tensorów tworząc nowy wymiar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__2fIhfoDzdD"
      },
      "outputs": [],
      "source": [
        "print(f\"{x.shape=}\")\n",
        "print(f\"{x.ndim=}\")\n",
        "print()\n",
        "\n",
        "t1 = torch.cat([x, x, x], dim=1)\n",
        "print(f\"{t1.shape=}\")\n",
        "print(f\"{t1.ndim=}\")\n",
        "print()\n",
        "\n",
        "t2 = torch.stack([x, x, x], dim=1)\n",
        "print(f\"{t2.shape=}\")\n",
        "print(f\"{t2.ndim=}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTgnI5sJFNfT"
      },
      "source": [
        "###Operacje matematyczne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d03iVVQuHQCb"
      },
      "source": [
        "Metoda `t()` zwraca macierz transponowaną."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6C-gg9NHYFE"
      },
      "outputs": [],
      "source": [
        "m = torch.rand((2, 3))\n",
        "print(m)\n",
        "print()\n",
        "print(m.t())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e9xSvvDFzm6"
      },
      "source": [
        "Funkcja `mul` i operator `*` oblicza iloczyn po współrzędnych (iloczyn Hadamarda, oznaczany $\\odot$) macierzy.\n",
        "Funkcja `matmul` i operator `@` oblicza standardowy iloczyn macierzy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZY3YEMyFNBX"
      },
      "outputs": [],
      "source": [
        "m = torch.rand((2, 3))\n",
        "print(m)\n",
        "\n",
        "print(\"\\nIloczyn po współrzędnych m * m\")\n",
        "print(m * m)\n",
        "\n",
        "print(\"\\nStandardowy iloczyn macierzy m @ m.t()\")\n",
        "print(m @ m.t())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1diU0mjHlhO"
      },
      "source": [
        "Metody z postfiksem `_` w nazwie wykonują się w miejscu (*in-place*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57OOLJotHt50"
      },
      "outputs": [],
      "source": [
        "print(m, \"\\n\")\n",
        "m.add_(5)\n",
        "print(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Uwaga:** Tensory będące argumentami funkcji muszą znajdować się na tym samym urządzeniu."
      ],
      "metadata": {
        "id": "7WKdEx2b4mKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones((4, 4) , device='cpu')\n",
        "y = torch.ones((4, 4), device='cpu')\n",
        "\n",
        "print(x + y)\n",
        "\n",
        "y = y.to('cuda')\n",
        "print(x + y)\n",
        "# Błąd, tensory na różnych urządzeniach"
      ],
      "metadata": {
        "id": "tesYOIcp4mRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmgRb2OxIllp"
      },
      "source": [
        "W bibliotece PyTorch zaimplementowano wiele operacji matematycznych na tensorach:\n",
        "- Operacje arytmetyczne: `abs`, `ceil`, `floor`, `exp`, `log`, `trunc`, `sign`, `sqrt`, ...\n",
        "- Funkcje trygonometryczne: `sin`, `cos`, `tan`, `asin`, `acos`, `atan`, ...\n",
        "- Operacje na bitach: `bitwise_not`, `bitwise_and`, `bitwise_or`, `bitwise_xor`, `bitwise_left_shift`, ...\n",
        "- Operacje logiczne: `logical_not`, `logical_and`, `logical_or`, ...\n",
        "\n",
        "Listę dostępnych operacji matematycznych znajdziesz tutaj: [link](https://pytorch.org/docs/stable/torch.html#math-operations)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hos9UPiSKv4C"
      },
      "source": [
        "Inne operacje na tensorach:\n",
        "*   Operacje redukcji: `argmax`, `argmin`, `max`, `min`, `mean`, `std`, `median`, `mode`, `quantile`, `norm`, `sum`, `any`, `all`, `count`, `unique`. Pełna lista: [link](https://pytorch.org/docs/stable/torch.html#reduction-ops).\n",
        "*   Operacje sortowania i porównywania: `argsort`, `kthvalue`, `sort`, `topk`. Pełna lista: [link](https://pytorch.org/docs/stable/torch.html#comparison-ops).\n",
        "*   Metody algebry liniowej: `inv`, `det`, `eig`, `svd`, `lstsq`. Pełna lista: ([link](https://pytorch.org/docs/stable/linalg.html)).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((3,5)) * 10 - 5\n",
        "print(x)\n",
        "\n",
        "# Operacje redukcji po wszystkich elementach tensora\n",
        "print(f\"{x.min()=}\")\n",
        "print(f\"{x.max()=}\")\n",
        "print(f\"{x.mean()=}\")\n",
        "print(f\"{x.sum()=}\")\n",
        "print(f\"{x.sum()=}\")\n",
        "print(f\"{x.norm()=}\")\n",
        "print()\n",
        "# Operacje reukcji po okreslonym wymiarze\n",
        "print(f\"{x.min(dim=1)=}\")\n",
        "print(f\"{x.max(dim=0)=}\")\n",
        "print(f\"{x.mean(dim=0)=}\")\n",
        "print(f\"{x.sum(dim=1)=}\")\n",
        "print(f\"{x.norm(dim=1)=}\")"
      ],
      "metadata": {
        "id": "iRpn97H46OV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zZLR6Hw-L6c"
      },
      "source": [
        "###Konwencja sumacyjna Einsteina"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okPBou8IMDN-"
      },
      "source": [
        "Konwencja sumacyjna Einsteina to sposób zapisu operacji na macierzach i tensorach.\n",
        "Pozwala zwięźle zapisać złożone operacje na wielowymiarowych tablicach.\n",
        "Podstawowe zasady konwencji Einsteina:\n",
        "\n",
        "*   Indeksy (np. $i$, $j$, $k$) reprezentują osie tensora (np. wiersze, kolumny, głębokość w przypadku 3D) używane w obliczeniach.\n",
        "\n",
        "*   Wynik jest obliczany przez **zsumowanie iloczynu elementów** o podanych indeksach **po osiach których indeksy nie są podane w wyrażeniu wynikowym**.\n",
        "\n",
        "W PyTorch funkcja `torch.einsum` wykonuje wyrażenia zapisane w konwencji Einsteina. Na przykład mnożenie macierzy `A` i `B` może zostać zapisane jako `torch.einsum('ik,kj->ij', A, B)`. W tym przypadku sumowanie odbywa się po indeksie `k` (ponieważ nie występuje w wyrażeniu wynikowym) a wynikowa macierz jest indeksowana `i` i `j` (czyli ma tyle wierszy ile macierz `A` i tyle kolumn ile macierz `B`)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Przykłady\n",
        "\n",
        "**Iloczyn skalarny** wektorów $\\mathbf{a}=[a_1,\\ldots, a_n]$ i $\\mathbf{b}=[b_1,\\ldots, b_n]$ jest zdefiniowany jako: $$c=\\sum_i a_i b_i $$.\n",
        "\n"
      ],
      "metadata": {
        "id": "xc-BTqOSWKLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([4, 5, 6])\n",
        "\n",
        "# Iloczyn skalarny\n",
        "# Sumowanie po indeksie i ponieważ nie występuje w wynikowym wyrażeniu\n",
        "# Wynikiem jest skalar, poniważ w wynikowym wyrażeniu nie ma indeksów\n",
        "result = torch.einsum('i,i->', a, b)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "At6xs6W2X3Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mnożenie macierzy** $\\mathbf{A}$ i $\\mathbf{B}$ jest zdefiniowane jako: $$C_{ij}=\\sum_k A_{ik} B_{kj}$$"
      ],
      "metadata": {
        "id": "ZwK88RU9YmxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.tensor([[1, 2], [3, 4]])\n",
        "B = torch.tensor([[5, 6], [7, 8]])\n",
        "\n",
        "C = torch.einsum('ik,kj->ij', A, B)\n",
        "# Sumowanie po indeksie k ponieważ nie występuje w wynikowym wyrażeniu\n",
        "\n",
        "print(C)"
      ],
      "metadata": {
        "id": "lCVpz86-Ym5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iloczyn zewnętrzny** wektorów $\\mathbf{a}=[a_1,\\ldots, a_n]$ i $\\mathbf{b}=[b_1,\\ldots, b_n]$ jest zdefiniowany jako: $$C_{ij}=a_i b_j $$.\n"
      ],
      "metadata": {
        "id": "9HF1yPbrYnCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([4, 5])\n",
        "\n",
        "C = torch.einsum('i,j->ij', a, b)\n",
        "print(C)"
      ],
      "metadata": {
        "id": "op80BW-HYnKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Porównanie czasów działania CPU versus GPU"
      ],
      "metadata": {
        "id": "RlVYUNqM6Pe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Porównanie czasów mnożenia dużych macierzy na CPU i GPU."
      ],
      "metadata": {
        "id": "5p8_oEmE6kch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "WydvrqSm6lL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_time(device, size=1000):\n",
        "    # Utwórz losowe macierze\n",
        "    a = torch.rand(size, size, device=device)\n",
        "    b = torch.rand(size, size, device=device)\n",
        "\n",
        "    if device.type == \"cuda\":\n",
        "        #Wait for all kernels in all streams on a CUDA device to complete.\n",
        "        torch.cuda.synchronize()\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Mnożenie macierzy\n",
        "    c = torch.matmul(a, b)\n",
        "\n",
        "    if device.type == \"cuda\":\n",
        "        #Wait for all kernels in all streams on a CUDA device to complete.\n",
        "        torch.cuda.synchronize()\n",
        "    end_time = time.time()\n",
        "\n",
        "    return end_time - start_time"
      ],
      "metadata": {
        "id": "UgU8O6lF6mhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = 10000\n",
        "device_cpu = torch.device(\"cpu\")\n",
        "device_gpu = torch.device(\"cuda\")\n",
        "\n",
        "print(f\"Rozmiar macierzy: {size}x{size}\")\n",
        "cpu_time = measure_time(device_cpu, size)\n",
        "print(f\"Czas wykonania na CPU: {cpu_time:.6f} s.\")\n",
        "\n",
        "gpu_time = measure_time(device_gpu, size)\n",
        "print(f\"Czas wykonania na GPU: {gpu_time:.6f} s.\")\n",
        "\n",
        "# Calculate speedup\n",
        "speedup = cpu_time / gpu_time\n",
        "print(f\"Przyśpieszenie (CPU/GPU): {speedup:.2f}x\")"
      ],
      "metadata": {
        "id": "Lp1UBLNa6m06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbCCBCeVP-KM"
      },
      "source": [
        "##Przykłady"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Analiza głównych składowych (PCA)\n",
        "\n",
        "Implementacja metody analizy głównych składowych (*principal component analysis*) w PyTorch.\n",
        "Opis metody PCA: [link](https://pl.wikipedia.org/wiki/Analiza_g%C5%82%C3%B3wnych_sk%C5%82adowych)."
      ],
      "metadata": {
        "id": "qifWiIXz9PwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Wygeneruj silnie skorelowane syntetyczne dane\n",
        "num_samples = 1000\n",
        "mean = [5, 10]\n",
        "cov = [[3, 2], [2, 2]]      # Macierz kowariancji\n",
        "data = np.random.multivariate_normal(mean, cov, num_samples)\n",
        "\n",
        "# Przekształć na tensor\n",
        "data_tensor = torch.tensor(data, dtype=torch.float32, device='cuda')"
      ],
      "metadata": {
        "id": "qyOlqQYr-eFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Krok 1: Centrowanie danych\n",
        "data_mean = data_tensor.mean(dim=0)\n",
        "centered_data = data_tensor - data_mean\n",
        "\n",
        "# Krok 2: Wyznaczenie macierzy kowariancji\n",
        "cov_matrix = torch.mm(centered_data.T, centered_data) / (num_samples - 1)\n",
        "\n",
        "# Krok 3: Dekompozycja względem wartości własnych\n",
        "# Macierz kowariancji jest symetryczna - możemy użyć eigh zamiast eig\n",
        "eigenvalues, eigenvectors = torch.linalg.eigh(cov_matrix)\n",
        "print(f\"Wartości własne macierz kowariancji: {eigenvalues}\")\n",
        "print(f\"Wektory własne macierz kowariancji: \\n{eigenvectors}\")\n",
        "\n",
        "# Step 4: Posortuj względem malejących wartości własnych\n",
        "sorted_indices = torch.argsort(eigenvalues, descending=True)\n",
        "sorted_eigenvalues = eigenvalues[sorted_indices]\n",
        "sorted_eigenvectors = eigenvectors[:, sorted_indices]"
      ],
      "metadata": {
        "id": "p3Sr9Fv6-eMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(data[:, 0], data[:, 1], alpha=0.5, label=\"Dane wejściowe\")\n",
        "origin = data_mean.cpu().numpy()  # Punkt zaczepienia wektorów\n",
        "for i in range(sorted_eigenvectors.shape[1]):\n",
        "    vector = sorted_eigenvectors[:, i].cpu().numpy()\n",
        "    scale = sorted_eigenvalues[i].sqrt().item()\n",
        "    plt.quiver(origin[0], origin[1], vector[0] * scale, vector[1] * scale,\n",
        "               angles='xy', scale_units='xy', scale=1)\n",
        "\n",
        "plt.xlabel(\"Cecha 1\")\n",
        "plt.ylabel(\"Cecha 2\")\n",
        "plt.title(\"Dystrybucja danych\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xZP6m-BQCv8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Regresja liniowa\n",
        "\n",
        "Niech dany będzie zbiór obserwacji (punktów) $(x_n, y_n) \\in \\mathbb{R}^2, n=1, \\ldots, N$.\n",
        "Celem jest wyznaczenie współczynników funkcji liniowej najlepiej dopasowanej do zbioru obserwacji.\n",
        "Przykładowy zbiór obserwacji `data`  zawiera pary (wiek pacjenta, zmierzone skurczowe ciśnienie krwi)."
      ],
      "metadata": {
        "id": "CyxacWkB9lUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(39, 144), (47, 220), (45, 138), (47, 145), (65, 162), (46, 142),\n",
        "        (67, 170), (42, 124), (67, 158), (56, 154), (64, 162), (56, 150),\n",
        "        (59, 140), (34, 110), (42, 128)]"
      ],
      "metadata": {
        "id": "oGJ9L_QCAQF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem możemy sformalizować jako znalezienie współczynników funkcji $f(x) = ax+b$ minimalizujących błąd średniokwadratowy:\n",
        "$$\n",
        "\\frac{1}{N}\\sum_{n=1}^{N} \\left( f \\left(x_n\\right) - y_n \\right)^2\n",
        "=\n",
        "\\frac{1}{N}\\sum_{n=1}^{N} \\left( a x_n + b - y_n \\right)^2\n",
        "\\, .$$\n",
        "W postaci macierzowej problem możemy przedstawić, jako znalezienie przybliżonego rozwiązania nadokreślonego układu równań liniowych minimalizującego błąd średniokwadratowy:\n",
        "$$\n",
        "\\begin{align}\n",
        "        \\begin{pmatrix}\n",
        "        x_1 & 1 \\\\\n",
        "        x_2 & 1 \\\\\n",
        "        \\ldots & \\ldots \\\\\n",
        "        x_N & 1\n",
        "        \\end{pmatrix}\n",
        "        \\begin{pmatrix}\n",
        "        a  \\\\\n",
        "        b  \\\\\n",
        "        \\end{pmatrix}\n",
        "        =        \n",
        "        \\begin{pmatrix}\n",
        "        y_1  \\\\\n",
        "        y_2  \\\\\n",
        "        \\ldots \\\\\n",
        "        y_N\n",
        "        \\end{pmatrix}\n",
        "    \\end{align}\n",
        "$$\n",
        "\n",
        "Do rozwiązania wykorzystamy funkcję `torch.linalg.lstsq` znajdującej przybliżone rozwiązanie nadokreślonego układu równań liniowych minimalizujące błąd średniokwadratowy. Patrz: [link](https://pytorch.org/docs/stable/generated/torch.linalg.lstsq.html#torch-linalg-lstsq).\n"
      ],
      "metadata": {
        "id": "fANVUSS-CdCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(data)\n",
        "x_values, y_values = zip(*data)\n",
        "\n",
        "x = torch.ones((n, 2))\n",
        "x[:, 0] = torch.tensor(x_values, dtype=torch.float32)\n",
        "print(f\"{x=}\")\n",
        "\n",
        "y = torch.tensor(y_values, dtype=torch.float32)\n",
        "print(f\"{y=}\")\n",
        "\n",
        "alpha = torch.linalg.lstsq(x, y).solution\n",
        "a = alpha[0].item()\n",
        "b = alpha[1].item()\n",
        "print(f\"Wyznaczone parametry: {a=:.4f}, {b=:.4f}\")"
      ],
      "metadata": {
        "id": "Zw-6AwbIA-WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wizualizacja danych pomiarowych i wyznaczonej prostej regresji liniowej."
      ],
      "metadata": {
        "id": "qLnsFSLSuCAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = [e[0] for e in data]\n",
        "y_data = [e[1] for e in data]\n",
        "\n",
        "x_min = min(x_data)\n",
        "x_max = max(x_data)\n",
        "\n",
        "x_line = torch.linspace(x_min, x_max, 100)\n",
        "y_line = a * x_line + b\n",
        "\n",
        "plt.scatter(x_data, y_data, color='blue', label='Punkty pomiarowe')\n",
        "plt.plot(x_line, y_line, color='green', label='')\n",
        "\n",
        "plt.xlabel('Wiek')\n",
        "plt.ylabel('Ciśnienie skurczowe')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PWrbIS22Kom2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}