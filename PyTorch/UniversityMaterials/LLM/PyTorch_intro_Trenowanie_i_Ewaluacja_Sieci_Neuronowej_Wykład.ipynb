{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch Intro - Trenowanie i Ewaluacja Sieci Neuronowej - Wykład\n",
        "Notatnik demonstruje implementację, trenowanie i ewaluację klasyfikatora opartego o sieć neuronowną o architekturze wielowarstwowego perceptronu (MLP - *multi-layer perceptron*).\n",
        "\n",
        "W notatniku wykorzystano następujące narzędzia:\n",
        "-  **PyTorch** - biblioteka głębokiego uczenia (tworzenie, trenowanie i ewaluacja głębokich sieci neuronowych). [link](https://pytorch.org/)\n",
        "-   **PyTorch Lightning** - biblioteka upraszczająca implementację pętli trenowania i ewaluacji modeli w PyTorch. [link](https://lightning.ai/docs/pytorch/stable/)\n",
        "-  Mobuł **Datasets** z biblioteki **HuggingFacce** - dostęp do wielu zbiorów danych z różnych dziedzin (audio, wizja komputerowa, przetwarzanie języka naturalnego). [link](https://huggingface.co/docs/datasets/index)\n",
        "-   **W&B (*Weights and Biases*) Models** - serwis w chmurze do zarządzania eksperymentami, monitorowania przebiegu treningu i logowania wyników ewaluacji modeli. [link](https://wandb.ai/site)\n",
        "-   **TorchMetrics** - biblioteka ponad 100 metryk do ewaluacji różnych typów modeli uczenia maszynowego. [link](https://lightning.ai/docs/torchmetrics/stable/)"
      ],
      "metadata": {
        "id": "KD8xISdCAOKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Przygotowanie środowiska\n",
        "Upewnij się, że notatnik jest uruchomiony na maszynie z GPU. Jesli GPU nie jest dostępne zmień typ maszyny (Runtime | Change runtime type) i wybierz T4 GPU."
      ],
      "metadata": {
        "id": "jJZnxX7rDoWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Wug8WJs7LQPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalacja dodatkowych bibliotek: datasets (z biblioteki HuggingFace), TorchMetrics i W&B (Weights and Biases) Models."
      ],
      "metadata": {
        "id": "QmhzFKNXUmDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets\n",
        "!pip install -q torchmetrics\n",
        "!pip install -q wandb"
      ],
      "metadata": {
        "id": "kuEVGjrJSt5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import bibliotek."
      ],
      "metadata": {
        "id": "yz1EcTToUUIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"Wersja biblioteki PyTorch: {torch.__version__}\")"
      ],
      "metadata": {
        "id": "zdGVyE77UU7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdzenie dostępności GPU."
      ],
      "metadata": {
        "id": "Jzr77SCyIZmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dostępność GPU: {torch.cuda.is_available()}\")\n",
        "print(f\"Typ GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "id": "7ZMytRxqU_6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Klasyfikacja sentymentu tekstu w języku naturalnym\n",
        "Problemem rozwiązywanym w notatniku jest **klasyfikacja sentymentu**, czyli określenie wydźwięku emocjonalnego tekstu w języku naturalnym.\n",
        "Dla podanego tekstu w języku angielskim należy określić czy ma on wydźwięk negatywny czy pozytywny (klasyfikacja dwuklasowa).\n",
        "\n",
        "W notatniku problem klasyfikacji sentymentu rozwiążemy bez wykorzystania wielkich modeli językowych.\n",
        "Zastosujemy tradycyjne podejście oparte o reprezentację typu **worek słów (*bag-of-words*)**  w którym analizowany tekst reprezentowany jest jako nieuporządkowana kolekcja (worek) słów. Pozycja słowa w tekście nie ma znaczenia, uwzględniana jest tylko liczba jego wystąpień. Więcej informacji znajdziesz tutaj: [link](https://en.wikipedia.org/wiki/Bag-of-words_model).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jWXHh8FRVHFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pobranie danych\n",
        "Wykorzystamy zbiór danych Yelp Polarity zawierający prawie 600 tysięcy opinii z serwisu Yelp wraz z numeryczną etykietą określającą sentyment wypowiedzi (0: negatywny i 1:pozytywny).\n",
        "Biblioteka HuggingFace (moduł datasets) udostępnia setki zbiorów danych z różnych dziedzin (audio, wizja komputerowa, przetwarzanie języka naturalnego). Więcej informacji: [link](https://huggingface.co/docs/datasets/index).\n",
        "\n",
        "Polecenie `load_dataset` pobiera zbiór danych złożony z części treningowej (`dataset[\"train\"]`) i testowej (`dataset[\"test\"]`).\n",
        "Zgodnie z dobrą praktyką z części treningowej wydzielimy dodatkową część walidacyjną.\n",
        "Z uwagi na ograniczenia sprzętowe platformy COLAB rozmiar każdej części zbioru danych (treningowej, walidacyjnej i testowej) zostanie ograniczony."
      ],
      "metadata": {
        "id": "DxVTXKITbnth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"fancyzhx/yelp_polarity\")\n",
        "print(dataset)\n",
        "\n",
        "test_dataset = dataset[\"test\"]\n",
        "\n",
        "# Wydziel część walidacyjną ze zbioru treningowego\n",
        "split_dataset = dataset[\"train\"].train_test_split(test_size=0.2)  # 80% train, 20% validation\n",
        "train_dataset = split_dataset[\"train\"]\n",
        "val_dataset = split_dataset[\"test\"]\n",
        "\n",
        "# Utwórz mniejsze podzbiory treningowe, walidacyjne i testowe\n",
        "train_dataset = train_dataset.shuffle().select(range(int(len(train_dataset) * .15)))\n",
        "val_dataset = val_dataset.shuffle().select(range(int(len(val_dataset) * .1)))\n",
        "test_dataset = test_dataset.shuffle().select(range(int(len(test_dataset) * .4)))\n",
        "\n",
        "print(f\"Liczba próbek w zbiorze treningowym: {len(train_dataset)}\")\n",
        "print(f\"Liczba próbek w zbiorze walidacyjnym: {len(val_dataset)}\")\n",
        "print(f\"Liczba próbek w zbiorze testowym: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "0pTLWKYjQ1zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = train_dataset[123]\n",
        "print(f\"\\nPrzykładowy element ze zbioru danych:\")\n",
        "print(f\"{sample['text']=}\")\n",
        "print(f\"{sample['label']=}\")"
      ],
      "metadata": {
        "id": "SYl-X5c_bCdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdzenie liczby elementów z każdej klasy w zbiorze treningowym."
      ],
      "metadata": {
        "id": "U86nR2t-b6mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count occurrences of each label\n",
        "unique_labels, counts = np.unique(train_dataset['label'], return_counts=True)\n",
        "\n",
        "# Plot histogram\n",
        "plt.bar(unique_labels, counts, color=['skyblue', 'orange'], edgecolor='black')\n",
        "plt.title('Histogram of Binary Labels')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(unique_labels)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a4-SGRLVla-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ekstrakcja cech\n",
        "Do ekstrakcji cech z tekstu wykorzystamy **metodę TF-IDF** (*term frequency-inverse document frequency*) opartą o podejście typu worek słów (*bag-of-words*). TF-IDF wyznacza miarę istotności (wagę) słów w dokumencie (tekście) będącym częścią większego zbioru dokumentów (korpusu tekstowego). TF-IDF jest obliczane dla każdego słowa jako iloczyn dwóch wartości:\n",
        "$$\\textit{tf-idf} = \\textit{tf} \\cdot \\textit{idf}$$\n",
        "gdzie $\\textit{tf}\\ $ jest czynnikiem zależnym od względnej częstości słowa w dokumencie, a $\\textit{idf}\\ $ jest tym mniejsze im w większej liczbie dokumentów występuje słowo, np.:\n",
        "$$\\textit{idf} = \\log \\frac{1+n}{1+\\textit{df}(t)} + 1 \\, ,$$\n",
        "gdzie $n$ jest liczbą wszystkich dokumentów a $\\textit{df}(t)$ liczbą dokumentów w których występuje słowo $t$.\n",
        "Intuicja jest taka, że bardzo często występujące słowa (np. *a*, *the*, *and*) nie są informatywne.\n",
        "Więcej informacji: [link](https://en.wikipedia.org/wiki/Tf%E2%80%93idf).\n",
        "\n",
        "Funkcja `TfidfVectorizer` z biblioteki `scikit-learn` tworzy rzadką macierz cech TF-IDF na podstawie zbioru dokumentów testowych. Każdy wiersz macierzy reprezentuje jeden dokument ze zbioru a kolumny zawierają wagi każdego słowa wyznaczone metodą TF-IDF.\n",
        "Aby zmniejszyć rozmiar wynikowej macierzy wykorzystamy parametr `max_features` aby ograniczyć liczbę słów (i co za tym idzie kolumn macierzy) do 10 tysięcy najczęściej występujących."
      ],
      "metadata": {
        "id": "l_LuNQ-kbbEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "QYosHRa4IZr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vocab_size = 10000\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=vocab_size,    # Ogranicz do max_features najczęściej występujących słów\n",
        "    lowercase=True,             # Przekształć na małe litery\n",
        "    analyzer='word',            # Analiza na poziomie słów (a nie pojedynczych znaków)\n",
        "    ngram_range=(1, 1),         # Unigramy (pojedynczne słowa)\n",
        "    stop_words=\"english\"        # Usuń częste słowa w języku angielskim (np. a, the, and)\n",
        ")\n",
        "\n",
        "# Ekstrakcja cech\n",
        "# Na zbiorze treningowym stosujemy funkcję fit_transform() która wyznacza cech i dokonuje ich ekstrakcji\n",
        "train_tfidf_features = vectorizer.fit_transform(train_dataset[\"text\"])\n",
        "# Na zbiorze walidacyjnym i testowym stosujemy funkcję transform() które dokonuje ekstrakcji tych samych cech co na zbiorze treningowym\n",
        "val_tfidf_features = vectorizer.transform(val_dataset[\"text\"])\n",
        "test_tfidf_features = vectorizer.transform(test_dataset[\"text\"])"
      ],
      "metadata": {
        "id": "iSJr9-I8Q12D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Rozmiar macierzy TF-IDF dla zbioru treningowego: {train_tfidf_features.shape}\")\n",
        "print(f\"{train_tfidf_features.dtype=}\\n\")\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(f\"Liczba cech: {len(feature_names)}\")\n",
        "print(f\"Przykładowe cechy: {np.random.choice(feature_names, 20)}\\n\")"
      ],
      "metadata": {
        "id": "NpgIs-zsv1-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyświetlenie wektora cech dla wybranego elementu zbioru treningowego."
      ],
      "metadata": {
        "id": "czUe3bb4zAB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ndx = 111\n",
        "print(f\"Element zbioru treningowego o indeksie={ndx}\")\n",
        "print(f\"{train_dataset['text'][ndx]=}\\n\")\n",
        "features = train_tfidf_features[ndx]\n",
        "print(f\"Cechy elementu o indeksie={ndx}:\")\n",
        "non_zero_cols = features.nonzero()[1]\n",
        "\n",
        "non_zero_cols = sorted(non_zero_cols)\n",
        "for i in non_zero_cols:\n",
        "    print(f\"Kolumna: {i} ({feature_names[i]})   Waga: {features[0, i]:.5f}\")"
      ],
      "metadata": {
        "id": "B99ewb0nzM77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram liczby niezerowych cech elementów zbioru treningowego.\n",
        "Jak widać, macierz cech `train_tfidf_features` jest bardzo rzadka - średnio niecałe 50 cech (kolumn macierzy `train_tfidf_features`) z 10 tysięcy jest niezerowe."
      ],
      "metadata": {
        "id": "TGlPToRly7rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_tfidf_features jest rzadką macierzą w formacie CSR (compressed sparse row matrix)\n",
        "# Poniższy trik pozwala szybko wyznaczyć liczbę niezerowych elementów w każdym wierszu\n",
        "# .indptr jest N+1 elementową tablicą taką, że indptr[i+1]-indptr[i] jest liczbą niezerowych wartości w i-tym wierszu\n",
        "# Patrz: https://stackoverflow.com/questions/52299420/scipy-csr-matrix-understand-indptr\n",
        "\n",
        "non_zero_counts = np.diff(train_tfidf_features.indptr)\n",
        "print(f\"Średnia liczba niezerowych cech w próbkach: {non_zero_counts.mean():.2f}\")\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(non_zero_counts, bins=64)\n",
        "plt.title('Histogram liczby niezerowych cech w próbce')\n",
        "plt.xlabel('Liczba niezerowych cech')\n",
        "plt.ylabel('Liczba próbek')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)"
      ],
      "metadata": {
        "id": "aI3yB74yfIj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Przygotowanie zbioru danych w PyTorch\n",
        "\n",
        "Biblioteka PyTorch implementuje mechanizmy umożliwiające dostęp do danych różnego typu (audio, obrazowe, tekstowe,...) w ustandaryzowany sposób. Do tego celu wykorzystywane są dwa rodzaje obiektów:\n",
        "*   **Zbiory danych (*Datasets*)** - umożliwiają dostęp do pojedyncznych elementów zbioru danych. Klasy implementujące dostęp do zbioru danych powinny być pochodnymi abstrakcyjnej klasy `torch.utils.data.Dataset`. Wyróżniamy dwa rodzaje zbiorów danych: mapowane (*map-style*) i iteracyjne (*iterable-style*).\n",
        "Najczęściej wykorzystywane mapowane zbiory danych umożliwiają dostęp do zindeksowanych elementów zbioru. Muszą implementować metody `__getitem__(ndx)` zwracającą element (np. sekwencję tekstową lub obraz wraz z etykietą) o indeksie `ndx` i `__len__()` zwracającą liczbę elementów zbioru danych.\n",
        "\n",
        "*   **Ładowarka danych (DataLoader)** -  klasa `torch.utils.data.DataLoader` pozwala opakować dostęp do zbioru danych i utworzyć iterator zwracający wsady treningowe złożone z wielu elementów. Pozwala wykorzystać wiele współbieżnych procesów roboczych w celu efektywnej budowy dużych wsadów treningowych."
      ],
      "metadata": {
        "id": "z_ImgYCH0upq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "AmkLyNCNIZ2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aby przygotować dane do trenowania modelu w PyTorch należy:\n",
        "1.   Zaimplementować klasę definiującą dostęp do zbioru danych - dziedziczącą z `torch.utils.data.Dataset` z metodami `__getitem__(ndx)` i `__len__()`.\n",
        "Metoda `__getitem__(ndx)` powinna zwracać element zbioru danych o indeksie `ndx` wraz z etykietą.\n",
        "Alternatywnie można wykorzystać zaimplementowaną w PyTorch klasę definiującą dostęp do publicznie dostępnego zbioru danych, patrz: [link](https://pytorch.org/vision/stable/datasets.html).\n",
        "2.   Dla każdej części zbioru danych (treningowej, walidacyjnej i testowej) utworzyć obiekt zaimplementowanej klasy.\n",
        "3.   Dla każdej części zbioru danych utworzyć ładowarkę danych klasy `torch.utils.data.DataLoader` zwracającą wsady treningowe złożone z wielu elementów.\n",
        "\n",
        "W naszym przypadku, elementy zbioru danych są już wczytane do pamięci.\n",
        "Dla części treningowej cechy są zapisane w rzadkiej macierzy `train_tfidf_features` a etykiety w `train_dataset['label']`.\n",
        "Zamiast implementować własną klasę definiującą dostęp do zbioru danych przekształcimy zbiór danych do postaci tensorów i wykorzystamy klasę `torch.utils.data.TensorDataset`, dziedziczącą z `torch.utils.data.Dataset`, która tworzy obiekt zbioru danych na podstawie podanych tensorów."
      ],
      "metadata": {
        "id": "XVK5Xg3WmYkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(sparse_features, labels):\n",
        "    # Zamień rzadką macierz cech na zwykłą (gęstą) macierz ndarray\n",
        "    dense_features = sparse_features.astype(np.float32).todense()\n",
        "    # Utwórz zbiór danych na podstawie tensora z cechami i tensora z etykietami\n",
        "    dataset = TensorDataset(\n",
        "        torch.from_numpy(dense_features),\n",
        "        torch.tensor(labels, dtype=torch.int64)\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "# Utwórz trzy zbiory danych: treningowy, walidacyjny i testowy\n",
        "datasets = {\n",
        "    'train': make_dataset(train_tfidf_features, train_dataset['label']),\n",
        "    'val': make_dataset(val_tfidf_features, val_dataset['label']),\n",
        "    'test': make_dataset(test_tfidf_features, test_dataset['label'])\n",
        "}\n",
        "\n",
        "# Wyświetl przykładowy element\n",
        "print(datasets['train'][0])"
      ],
      "metadata": {
        "id": "RJKNFhgvQ17S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utworzenie ładowarek danych dla każdej części zbioru danych (treningowej, walidacyjnej i testowej). Przydatne parametry:\n",
        "- `batch_size` - rozmiar wsadu treningowego.\n",
        "- `shuffle` - czy wybierać elementy zbioru danych w losowej kolejności. Powinien być ustawiony na `True` tylko dla zbioru treningowego.\n",
        "- `num_workers` - liczba procesów roboczych ładowarki danych. Na COLAB zalecane jest ustawienie 0 (ładowarka danych działa w głównym procesie). Na innych platformach należy ustawić większe wartości, zależne od dostępnych zasobów obliczeniowych."
      ],
      "metadata": {
        "id": "JHaDMnhbe2ML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "\n",
        "dataloaders = {split: DataLoader(datasets[split], batch_size=batch_size, shuffle=split=='train', num_workers=0) for split in datasets}"
      ],
      "metadata": {
        "id": "52VzqYlBWA7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obiekt klasy `DataLoader` jest iteratorem generującym kolejne wsady danych. W naszym przypadku wsad złożony jest z dwóch części: tensora cech o rozmiarach `(batch_size=256, 10000)` i tensora etykiet o rozmiarze `(batch_size=256,)`.\n",
        "W ogólności wsady mogą mieć bardziej złożoną strukturę, np. słowniki których wartości są tensorami.\n"
      ],
      "metadata": {
        "id": "q31e_T6FhywM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for X_batch, y_batch in dataloaders['train']:\n",
        "    print(f\"{X_batch.shape=}\")\n",
        "    print(f\"{y_batch.shape=}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "n65dKaw9WA-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utworzenie modelu sieci neuronowej\n",
        "\n",
        "Modele sieci neuronowych implementujemy w PyTorch jako klasy dziedziczące z klasy `torch.nn.Module`. W metodzie `__init__(...)` tworzone są składowe architektury modelu, takie jak warstwy tworzące sieć neuronową.\n",
        "W metodzie `forward(...)` zaimplementowana jest logika przetwarzania wejściowego tensora (bądź tensorów) przez sieć. Wywoływane są kolejne warstwy sieci z odpowiednimi argumentami i zwracany jest wynikowy tensor.\n",
        "\n",
        "W notatniku zaimplementujemy klasyfikator jako perceptron wielowarstwowy złożony z kilku warstw liniowych `torch.nn.Linear` oddzielonych warstwami nieliniowymi `torch.nn.ReLU`.\n",
        "\n",
        "**WAŻNE:** Klasa definiująca sieć neuronową bądź moduł sieci neuronowej musi być pochodną klasy `torch.nn.Module`.\n",
        "Architekturę modelu rozbijemy na dwie części:\n",
        "- **Blok ekstrakcji cech** (`self.feature_extractor`). Wykorzystamy klasę `torch.nn.Sequential` aby połączyć dwie warstwy liniowe i następujące po nich nieliniowości w jeden sekwencyjny blok. Zauważmy, że rozmiar wejściowy pierwszej warstwy sekwencyjnej jest równy rozmiarowi wektora cech z bazy danych (`self.vocab_size`)\n",
        "- **Końcowej warstwy liniowego klasyfikatora** (`self.linear`). Rozmiar wyjściowy liniowego klasyfikatora jest równy liczbie klas (`n_classes=2` - sentyment negatywny lub pozytywny).\n",
        "Aby zmniejszyć ryzyko przeuczenia i poprawić generalizację sieci przed liniowym klasyfikatorem zastosujemy warstwę odrzutu `nn.Dropout`."
      ],
      "metadata": {
        "id": "j3NKbrnrjkcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, vocab_size: int, n_classes: int):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Linear(self.vocab_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.linear = nn.Linear(16, n_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        features = self.feature_extractor(x)\n",
        "        features = self.dropout(features)\n",
        "        logits = self.linear(features)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "cQwelGp1WBAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "print(\"Urządzenie: {}\".format(device))"
      ],
      "metadata": {
        "id": "1oITuW4uIaAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utwórz model sieci neuronowej i prześlij na właściwe urządzenie\n",
        "classifier = SimpleNet(vocab_size, n_classes=2)\n",
        "classifier.to(device)\n",
        "\n",
        "print(classifier)"
      ],
      "metadata": {
        "id": "oTjifxNlWBDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Uwaga:** Aby przesłać moduł sieci neuronowej (obiekt klasy dziedziczącej z `nn.Module`) na urządzenie wystarczy polecenie:\n",
        "```\n",
        "model.to(device)\n",
        "```\n",
        "Aby przesłać tensor x na urządzenie należy napisać:\n",
        "```\n",
        "x = x.to(device)\n",
        "```\n",
        "Metoda `to(device)` dla tensora tworzy jego kopię na podanym urządzeniu (i zwraca referencję do kopii)."
      ],
      "metadata": {
        "id": "TEGQQOwbbYxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdzenie działania sieci na losowych danych.\n"
      ],
      "metadata": {
        "id": "sPXAmgEy91-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utworzenie 5-elementowego wsadu tensorów o vocab_size elementach każdy\n",
        "x = torch.rand((5, vocab_size))\n",
        "print(x)\n",
        "print(f\"{x.shape=}\\n\")\n",
        "\n",
        "x = x.to(device)        # Przenieś tensor na GPU\n",
        "\n",
        "logits = classifier(x)\n",
        "print(f\"{logits=}\")\n",
        "print(f\"{logits.shape=}\\n\")\n",
        "\n",
        "probabilities = nn.functional.softmax(logits, dim=-1)\n",
        "print(f\"{probabilities=}\")"
      ],
      "metadata": {
        "id": "KuGJ4Uzw92X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zauważmy, że dla każdego elementu zbioru danych sieć zwraca wektor dwóch wartości rzeczywistych z zakresu od minus do plus nieskończoności.\n",
        " Aby uzyskać rozkład prawdopodobieństwa klas należy zastosować funkcję `nn.functional.softmax` na wyjściu z modułu sieci zdefiniowaną jako:\n",
        "\n",
        " $$\\sigma(\\mathbf{z})_i = \\frac{exp{(z_i)}}{\\sum_j{\\exp(z_j)}} \\, ,$$\n",
        " gdzie $\\mathbf{z} =(z_{1},\\dotsc ,z_{K})\\in \\mathbb {R} ^{K}$ jest wektorem nieznormalizowanych wyjść z sieci.\n",
        "\n",
        "**WAŻNE:**\n",
        "Zwykle klasyfikatory oparte o sieci neuronowe zwracają wartości zwane **logitami** które możemy interpretować jako nieznormalizowane logarytmy prawdopodobieństwa.\n",
        "Ze względów numerycznych podczas trenowania modelu **funkcję straty należy wyznaczać na podstawie logitów**, a NIE w oparciu o prawdopodobieństwa klas.\n",
        "Z tego względu NIE należy stosować operacji softmax wewnątrz modułu sieci neuronowej. Moduł sieci powinien zwracać nieznormalizowane wartości (logity)."
      ],
      "metadata": {
        "id": "6vIjRO45As-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pętla treningowa\n",
        "\n",
        "Zaimplementowana poniżej funkcja `train` zawiera typową pętlę treningową modelu sieci neuronowej.\n",
        "\n",
        "*   Trening modelu jest podzielony na **epoki**. W czasie jednej epoki następuje jednokrotne przejście przez cały zbiór danych.\n",
        "*   Każda epoka podzielona jest na **dwie fazy** - fazę **treningu** (train) i **walidacji** (val).\n",
        "*   W każdej fazie iteracyjnie pobierane są kolejne **wsady** ze zbioru danych (treningowego albo walidacyjnego). Dla każdego wsadu wyznaczane są wartości funkcji straty (entropia krzyżowa) i metryki jakości modelu (dokładność). W fazie treningu dodatkowo wyznaczane są gradienty funkcji straty względem parametrów sieci (przejście w tył - `loss.backward()`) i optymalizowane są parametry sieci (`optimizer.step()`).\n",
        "\n",
        "**WAŻNE - specyfika PyTorcha:**\n",
        "\n",
        "*   Moduł sieci neuronowej może być w trybie treningowym (`train`) lub ewaluacyjnym (`eval`). W fazie trenowania model musi zostać przełączony w tryb treningowy poleceniem `model.train()`. W pozostałych fazach model **musi** zostać przełączony w tryb ewaluacji\n",
        "poleceniem `model.eval()`.\n",
        "Jeśli chcemy wykorzystać wytrenowany model do wnioskowania **należy pamiętać o przełączeniu go w tryb ewaluacji**, w przeciwnym przypadku wyniki działania sieci mogą być błędne.\n",
        "Różnice między trybem `train` i `eval`: [link](https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch).\n",
        "*   Domyślnie gradienty zapamiętywane w tensorach podlegających optymalizacji (wagach sieci) akumulują się po każdym wywołaniu przejścia w tył (metody `backward`).Dlatego konieczne jest wyzerowanie gradientów poleceniem `optimizer.zero_grad()`. Więcej informacji: [link](https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch).\n",
        "*   Wywołanie modułu sieci (klasy dziedziczącej z `nn.Module`) i wykonanie przejścia w przód wykonujemy poleceniem `model(X_batch)` a NIE `model.forward(X_batch)`. Nie należy bezpośrednio wywowyłać metody `forward`!\n",
        "\n"
      ],
      "metadata": {
        "id": "TN7gX5v6qtK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oprócz biblioteki PyTorch wykorzystamy następujące narzędzia:\n",
        "-   **W&B (*Weights and Biases*) Models** - serwis w chmurze do zarządzania eksperymentami, monitorowania przebiegu treningu i logowania wyników ewaluacji modeli. [link](https://wandb.ai/site)\n",
        "-   **TorchMetrics** - biblioteka ponad 100 metryk do ewaluacji różnych typów modeli uczenia maszynowego. [link](https://lightning.ai/docs/torchmetrics/stable/)"
      ],
      "metadata": {
        "id": "_xojKXve3-G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "\n",
        "\n",
        "def train(model: nn.Module, loaders: dict[DataLoader], criterion: nn.Module,\n",
        "          optimizer: torch.optim.Optimizer, lr_scheduler, num_epochs: int):\n",
        "\n",
        "    # Metryki wyznaczane dla wsadu\n",
        "    metric_loss = torchmetrics.aggregation.MeanMetric().to(device)\n",
        "    metric_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=2).to(device)\n",
        "\n",
        "    # Run all epochs\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            # WAŻNE - przełącz model w odpowiedni tryb\n",
        "            if phase == 'train':\n",
        "                model.train()  # Przełącz model w tryb treningowy\n",
        "            else:\n",
        "                model.eval()   # Przełącz model w tryb ewaluacyjny\n",
        "\n",
        "            # Loop over each batch in the data loader\n",
        "            for X_batch, target in tqdm(loaders[phase]):\n",
        "                # Przenieś dane na odpowiednie urządzenie\n",
        "                X_batch, target = X_batch.to(device), target.to(device)\n",
        "\n",
        "                # Wyzeruj gradienty parametrów sieci\n",
        "                # BARDZO WAŻNY KROK - domyślnie gradienty nie są zerowane i akumulują się dla wielu kroków przejścia w tył\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Przejście w przód (forward)\n",
        "                # Śledzenie historii obliczeń tylko w fazie trenowania\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    logits = model(X_batch)\n",
        "                    _, preds = torch.max(logits, dim=1)\n",
        "                    loss = criterion(logits, target)\n",
        "\n",
        "                    # Zaktualizuj wartości metryk\n",
        "                    metric_loss(loss)\n",
        "                    metric_acc(preds, target)\n",
        "\n",
        "                    # Przejście w tył (backward) i krok optymalizacji parametrów sieci tylko w fazie trenowania\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "            # Wyznacz średnie wartości metryk dla wsadu\n",
        "            acc = metric_acc.compute()\n",
        "            mean_loss = metric_loss.compute()\n",
        "            current_lr = lr_scheduler.get_last_lr()[0]\n",
        "            print(f\"(Epoch {epoch}/[{phase}]) Loss:\\t{mean_loss:.3f}   Accuracy: {acc:.3f}   lr: {current_lr}\")\n",
        "            metrics = {\n",
        "                f\"{phase}/loss\": mean_loss,\n",
        "                f\"{phase}/accuracy\": acc,\n",
        "                f\"{phase}/lr\": current_lr,\n",
        "            }\n",
        "            wandb.log(metrics, step=epoch)\n",
        "\n",
        "            # Wyzeruj metryki\n",
        "            metric_loss.reset()\n",
        "            metric_acc.reset()\n",
        "            # KONIEC JEDNEJ FAZY W EPOCE (TRENING LUB WALIDACJA)\n",
        "\n",
        "        lr_scheduler.step()\n",
        "        # KONIEC EPOKI\n"
      ],
      "metadata": {
        "id": "Gj7lURjo9m4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "W trenowaniu klasyfikatorów typowo wykorzystywana jest **funkcja straty entropii krzyżowej** (klasa `nn.CrossEntropyLoss`) między estymowanym a prawdziwym rozkładem prawdopodobieństwa.\n",
        "Jako argumenty obiektu `nn.CrossEntropyLoss` podajemy:\n",
        "*   **nieznormalizowane wyjścia z sieci neuronowej (logity)** w formie tensora rozmiaru $(N, C)$, gdzie $N$ jest rozmiarem wsadu a $C$ liczbą klas\n",
        "*   **identyfikatory prawdziwej klasy** w formie tensora rozmiaru $(N, )$zawierającego wartości z zakresu $0,\\ldots,C-1$ (identyfikatory klas rozpoczynają się od zera).\n",
        "\n",
        "**WAŻNE:** Ze względów numerycznych, do jako argument obiektu klasy `nn.CrossEntropyLoss` podajemy nieznormalizowane wyjście z sieci (logity) a NIE estymowane prawdopodobieństwo klas."
      ],
      "metadata": {
        "id": "1Ouvfe119LAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Niech $p$ będzie prawdziwym a $q$ estymowanym przez model rozkładem prawdopodobieństwa dyskretnej zmiennej losowej o wartościach $\\mathcal{X} = \\left\\{ 0, \\ldots, C-1 \\right\\}$ gdzie $C$ jest liczbą klas. **Entropia krzyżowa rozkładu $q$ względem $p$** jest dana jest wzorem:\n",
        "$$\n",
        "\\mathcal{L}_{CE} = - \\sum_{i \\in \\mathcal{X}} p_i \\log q_i\n",
        "$$\n",
        "\n",
        "Dla pojedynczej próbki ze zbioru danych prawdziwy rozkład prawdopodobieństwa $p$ ma rozkład punktowy $p_k = 1$, gdzie $k$ jest identyfikatorem prawdziwej klasy. Wartość funkcji entropii krzyżowej upraszcza się zatem do postaci:\n",
        "$$\n",
        "\\mathcal{l}_{CE} = - \\log q_k \\, ,\n",
        "$$\n",
        "gdzie $q_k$ jest estymowanym przez sieć prawdopodobieństwem prawdziwej klasy $k$.\n"
      ],
      "metadata": {
        "id": "iEiGs6SCO-q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 8\n",
        "\n",
        "# Utworzenie obiekty klasy nn.CrossEntropyLoss() obliczającego funkcję straty entropii krzyżowej\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Utworzenie optymalizatora AdamW\n",
        "optimizer = torch.optim.AdamW(classifier.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n",
        "# Utworzenie planisty stopy uczenia\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)"
      ],
      "metadata": {
        "id": "Q4GkM7jF9m7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "# Logowanie do serwisu Weights&Biases monitorującego przebieg eksperymentów\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "AG8JSlkmSc68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(project=\"MyExperiments\")\n",
        "\n",
        "train(classifier, dataloaders, criterion, optimizer, lr_scheduler, num_epochs)\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "Em0ihU6j9m-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Po zakończeniu trenowania modelu sprawdź przebiegi krzywych uczenia zalogowane w serwisie Weights&Biases: [link](https://wandb.ai/home).\n",
        "\n",
        "Do zapisania i wczytania wag wytrenowanego modelu z dysku oraz zapisania stanu procesu uczenia modelu wykorzystywane są funkcje:\n",
        "\n",
        "*   `torch.save` - zapisanie słownika stanu modelu na dysk.\n",
        "*   `torch.load` - załadowanie słownika stanu modelu z dysku\n",
        "*   `torch.nn.Module.load_state_dict` - ustawienie wag modułu sieci neuronowej z załadowanego słownika stanu modelu\n",
        "\n",
        "Zwyczajowo słownik stanu modelu zapisywany jest w plikach z rozszerzeniem\n",
        "`.pt` lub `.pth`.\n",
        "\n",
        "\n",
        "**Słownik stanu modelu** oprócz wag sieci neuronowej zawiera aktualne parametry optymalizatora. Dzięki temu, po wczytaniu słownika stanu z sieci możliwa jest kontynuacja przerwanego treningu modelu.\n",
        "Więcej informacji: [link](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n",
        "\n",
        "Zapisanie stanu modelu na dysku:\n",
        "```\n",
        "torch.save(model.state_dict(), PATH)\n",
        "```\n",
        "Wczytanie wag wytrenowanego modelu z dysku aby, wykorzystać go do inferencji:\n",
        "```\n",
        "model = TheModelClass(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, weights_only=True))\n",
        "model.eval()\n",
        "```\n",
        "**Uwaga:** Przed wykorzystaniem modelu do inferencji należy pamiętać o przełączeniu go w tryb ewaluacji `model.eval()`. Jeśli model nie zostanie przełączony w tryb ewaluacji niektóre warstwy (dropout, batch norm) nie będą działały poprawnie."
      ],
      "metadata": {
        "id": "ZckiFbCyUamm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(classifier.state_dict(), 'my_model_weights.pth')"
      ],
      "metadata": {
        "id": "HzILaW35UZpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ewaluacja modelu"
      ],
      "metadata": {
        "id": "9QnG8DjDq0XU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalna ewaluacja na zbiorze testowym + wszystkie metryki takie jak precyzja, odzysk per klasa, macierz pomyłek"
      ],
      "metadata": {
        "id": "GPf-RFF_Jdjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indeks elementu ze zbioru testowego\n",
        "ndx = 2\n",
        "\n",
        "x, target = datasets['test'][ndx]\n",
        "print(f\"Opinia: {test_dataset[ndx]['text']}\")\n",
        "print(f\"Prawdziwa klasa: {target}\")\n",
        "\n",
        "x = x.to(device)\n",
        "\n",
        "# BARDZO WAŻNE\n",
        "classifier.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    # torch.inference_mode - opcjonalne, ale przyśpiesz wykonanie, bo nie jest tworzony graf obliczeń\n",
        "    logits = classifier(x)\n",
        "\n",
        "print(f\"Wyjście z sieci (logity): {logits}\")\n",
        "probas = torch.nn.functional.softmax(logits, dim=-1)\n",
        "print(f\"Rozkład prawdopodobieństwa klas: {probas}\")\n",
        "print(f\"Predykowana klasa: {logits.argmax(dim=-1)}\")\n"
      ],
      "metadata": {
        "id": "TJaZlhpnORok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyznacz wyniki predykcji dla wszystkich elementów zbioru testowego.\n",
        "W tablicy `preds` zostanie zapisana predykowana klasa, a w tablicy\n",
        "`targets` prawdziwa klasa każdego elementu."
      ],
      "metadata": {
        "id": "YfYavQV-M-Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_l = []\n",
        "targets_l = []\n",
        "\n",
        "classifier.eval()\n",
        "\n",
        "for X_batch, target in tqdm(dataloaders['test']):\n",
        "    # Przenieś dane na odpowiednie urządzenie\n",
        "    X_batch, target = X_batch.to(device), target.to(device)\n",
        "\n",
        "    # Przejście w przód (forward)\n",
        "    # Śledzenie historii obliczeń tylko w fazie trenowania\n",
        "    with torch.inference_mode():\n",
        "        logits = classifier(X_batch)\n",
        "        _, preds = torch.max(logits, dim=-1)\n",
        "        preds_l.extend(preds.cpu().numpy())\n",
        "        targets_l.extend(target.cpu().numpy())\n",
        "\n",
        "preds = np.array(preds_l)\n",
        "targets = np.array(targets_l)\n",
        "\n",
        "print(f\"{preds.shape=}\")\n",
        "print(f\"{targets.shape=}\")"
      ],
      "metadata": {
        "id": "nMCeGVf9R9d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do ewaluacji modelu wykorzystamy bibliotekę scikit-learn. Dla każdej klasy wyznaczymy metryki: precyzja (*precision*), czułość (*recall*), miara f1 (*f1-score*)."
      ],
      "metadata": {
        "id": "UhXDLPcsNmpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Nazwy klas: 0=negatywna opinia, 1=pozytywna opinia\n",
        "labels = ['negatywna', 'pozytywna']\n",
        "\n",
        "report = classification_report(targets, preds, target_names = labels)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "IWD5-YBXY14F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyznaczenie macierzy pomyłek (*confusion matrix*). Wiersze macierzy pomyłek odpowiadają prawdziwej klasie, a kolumny predykowanej klasie."
      ],
      "metadata": {
        "id": "TRuj9sSJN_92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(targets, preds)\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.title('Macierz pomyłek')\n",
        "plt.xlabel('Predykowana klasa')\n",
        "plt.ylabel('Prawdziwa klasa')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-dDT2iAZYN_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dodatkowe materiały"
      ],
      "metadata": {
        "id": "gC5aZC1BRyAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trening modelu z wykorzystaniem biblioteki PyTorch Lightning\n",
        "\n",
        "PyTorch Lightning jest biblioteką pozwalającą na łatwiejszą implementację pętli treningowej w PyTorch, bez konieczności pisania powtarzalnych części kodu.\n",
        "Wspiera trenowanie modeli w rozproszonym środowisku na wielu GPU oraz trening w trybie mieszanej precyzji (*mixed precision*).\n",
        "Więcej informacji: [link](https://lightning.ai/docs/pytorch/stable/starter/introduction.html).\n",
        "\n",
        "Poniżej znajduje się przykładowa implementacja pętli treningowej zdefiniowanej wcześniej sieci neuronowej klasy `SimpleNet` z wykorzystaniem biblioteki PyTorch Lightning."
      ],
      "metadata": {
        "id": "jxDqSQFZN_0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q lightning"
      ],
      "metadata": {
        "id": "-9-f_glEcIrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch.loggers import WandbLogger"
      ],
      "metadata": {
        "id": "dfazSwGnl_Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "W pierwszym kroku należy opakować trenowany model w klasę dziedziczącą z klasy `lightning.LightningModule`. W tej klasie należy zdefiniować metody:\n",
        "*   `training_step(...)` - jeden krok treningowy (przetworzenie jednego wsadu ze zbioru treningowego)\n",
        "*   (opcjonalnie) `validation_step(...)` - jeden krok walidacyjny\n",
        "*   (opcjonalnie) `test_step(...)` - jeden krok testowy\n",
        "*  `configure_optimizers(...)` - konfiguracja optymalizatora i planisty stopy uczenia\n",
        "\n"
      ],
      "metadata": {
        "id": "0fIJa-r8Q9jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the LightningModule\n",
        "import lightning as L\n",
        "\n",
        "\n",
        "class LitNet(L.LightningModule):\n",
        "    def __init__(self, classifier: nn.Module):\n",
        "        super().__init__()\n",
        "        self.classifier = classifier\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.metric_train_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=2)\n",
        "        self.metric_val_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=2)\n",
        "        self.metric_test_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=2)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # training_step implementuje jeden krok pętli treningowej\n",
        "        x, target = batch\n",
        "        logits = self.classifier(x)\n",
        "        loss = self.criterion(logits, target)\n",
        "        self.log(\"train/loss\", loss, prog_bar=True)\n",
        "\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        self.metric_train_acc(preds, target)\n",
        "        self.log('train/accuracy', self.metric_train_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, target = batch\n",
        "        logits = self.classifier(x)\n",
        "        loss = self.criterion(logits, target)\n",
        "        self.log(\"val/loss\", loss, prog_bar=True)\n",
        "\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        self.metric_val_acc(preds, target)\n",
        "        self.log('val/accuracy', self.metric_val_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, target = batch\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        self.metric_test_acc(preds, target)\n",
        "        self.log('test/accuracy', self.metric_test_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.classifier.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
        "        return {\"optimizer\": optimizer,\"lr_scheduler\": lr_scheduler}"
      ],
      "metadata": {
        "id": "NcjQW5hvawBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init the network\n",
        "classifier = SimpleNet(vocab_size, n_classes=2)\n",
        "# Wrap in a lightning module\n",
        "lit_model = LitNet(classifier)"
      ],
      "metadata": {
        "id": "TCXoL9zueHlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utworzenie obiektu klasy `lightning.Trainer` implementującego logikę pętli treningowej."
      ],
      "metadata": {
        "id": "yEvaLDXsSb8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb_logger = WandbLogger(project=\"MyExperiments\")\n",
        "trainer = L.Trainer(max_epochs=num_epochs, logger=wandb_logger)"
      ],
      "metadata": {
        "id": "nAluyvCnd1sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rozpoczęcie treningu modelu."
      ],
      "metadata": {
        "id": "l67_hlouSWiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(\n",
        "    lit_model,\n",
        "    train_dataloaders=dataloaders['train'],\n",
        "    val_dataloaders=dataloaders['val']\n",
        "    )"
      ],
      "metadata": {
        "id": "n1hg_CjCmbhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Po zakończeniu trenowania modelu sprawdź przebiegi krzywych uczenia zalogowane w serwisie Weights&Biases: [link](https://wandb.ai/home).\n",
        "\n",
        "Ewaluacja wytrenowanego modelu na zbiorze testowym."
      ],
      "metadata": {
        "id": "kM1jHz1cXfQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(ckpt_path=\"best\", dataloaders=dataloaders['test'])"
      ],
      "metadata": {
        "id": "SGxjqSLsXOQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zakończ logowanie danych eksperymentu\n",
        "wandb_logger.experiment.finish()"
      ],
      "metadata": {
        "id": "MJsSRd98a_5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zwolnij pamięć\n",
        "del classifier\n",
        "del lit_model\n",
        "del trainer\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "zxgDDgXa8Ibc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Wykorzystanie statycznych wektorowych reprezentacji słów\n",
        "\n",
        "Jako alternatywa do wektoryzacji metodą TD-IDF wykorzystamy statyczne wektorowe reprezentacje słów wyznaczone z wykorzystaniem metody Word2Vec. Skorzystamy z biblioteki Gensim ([link](https://radimrehurek.com/gensim/)).\n",
        "Wektorową reprezentację dokumentu (opinii) wyznaczmy jako średnią z wektorowych reprezentacji słów w dokumencie. Podobnie jak w podejściu TD-IDF kolejność słów w dokumencie nie będzie uwzględniana.\n"
      ],
      "metadata": {
        "id": "nFKh5aM1R29b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pobierz i rozpakuj pretrenowany model dla języka angielskiego: GoogleNews-vectors-negative300.bin.gz\n",
        "!gdown 0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
        "!gzip -d GoogleNews-vectors-negative300.bin.gz"
      ],
      "metadata": {
        "id": "_hgh_EmNjiIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# Załaduj model\n",
        "model = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)"
      ],
      "metadata": {
        "id": "d24g388nR6o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdź wektorową reprezentację wybranego słowa."
      ],
      "metadata": {
        "id": "vLc3x_13p6Rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_vector = model[\"car\"]\n",
        "print(f\"Rozmiar wektorowej reprezentacji słowa: {word_vector.shape=}\")\n",
        "print(f\"Pierwsze 20 elementów wektorowej reprezentacji: {word_vector[:20]=}\")\n"
      ],
      "metadata": {
        "id": "mDBGTyuekfmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "#len(f\"Liczba słów/n-gramów w słowniku: {model.words}\")"
      ],
      "metadata": {
        "id": "sSstQ0D1UEzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Znajdź najbliższych sąsiadów podanego słowa, w sensie odległości kosinusowej, w przestrzeni reprezentacji."
      ],
      "metadata": {
        "id": "Bt5oGcFIYeYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'car'\n",
        "print(model.most_similar(word, topn=5))"
      ],
      "metadata": {
        "id": "NntbbLUPUI5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyznacz wektorową reprezentację dokumentu jako średnią z wektorowych reprezentacji słów w dokumencie."
      ],
      "metadata": {
        "id": "TRRoV-rBiPjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_document_vector(document, model):\n",
        "    tokens = simple_preprocess(document)\n",
        "    vectors = []\n",
        "    for word in tokens:\n",
        "        # Pomijamy słowa których nie ma w słowniku\n",
        "        if word in model:\n",
        "            vectors.append(model[word])\n",
        "\n",
        "    if len(vectors) == 0:\n",
        "        document_vector =  np.zeros(model.vector_size).astype(np.float32)\n",
        "    else:\n",
        "        document_vector = np.mean(vectors, axis=0).astype(np.float32)\n",
        "\n",
        "    return document_vector"
      ],
      "metadata": {
        "id": "M51FJjwJVnXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ndx = 101\n",
        "data_item = train_dataset[ndx]\n",
        "print(data_item)\n",
        "doc_embedding = compute_document_vector(data_item['text'], model)\n",
        "print(f\"\")\n",
        "print(f\"Rozmiar reprezentacji dokumentu: {doc_embedding.shape}\")"
      ],
      "metadata": {
        "id": "IpCGJOpVVnao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyzncz wektorowe reprezentacje wszystkich dokumentów w każdym ze zbiorów danych (treningowym, walidacyjnym i testowym)."
      ],
      "metadata": {
        "id": "VcYdkNm6ts_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "\n",
        "def make_dataset(hf_dataset):\n",
        "    doc_vectors = []\n",
        "    labels = []\n",
        "    for item in hf_dataset:\n",
        "        doc_vectors.append(compute_document_vector(item['text'], model))\n",
        "        labels.append(item['label'])\n",
        "    return TensorDataset(torch.tensor(doc_vectors), torch.tensor(labels))\n",
        "\n",
        "\n",
        "# Utwórz trzy zbiory danych: treningowy, walidacyjny i testowy\n",
        "datasets = {\n",
        "    'train': make_dataset(train_dataset),\n",
        "    'val': make_dataset(val_dataset),\n",
        "    'test': make_dataset(test_dataset)\n",
        "}\n",
        "\n",
        "# Wyświetl przykładowy element\n",
        "print(datasets['train'][0])"
      ],
      "metadata": {
        "id": "YDA9mpE4o2Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utwórz ładowarki danych (*Dataloaders*) dla każdego zbioru danych."
      ],
      "metadata": {
        "id": "tkXtNl8VvpDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "dataloaders = {split: DataLoader(datasets[split], batch_size=batch_size, shuffle=split=='train', num_workers=0) for split in datasets}"
      ],
      "metadata": {
        "id": "fEWT5BryqoHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wytrenujemy model klasyfikatora sentymentu tekstu w oparciu o wektorową reprezentację dokumentów. Wykorzystamy zaimplementowany wcześniej model wielowarstwowego perceptronu `SimpleNet`. Rozmiar wejścia będzie równy rozmiarowi wektorowej reprezentacji (`model.vector_size`) a rozmiar wyjścia równy 2 (dwie klasy: sentyment negatywny i pozytywny).\n",
        "\n",
        "Trening modelu przeprowadzimy z wykorzystaniem biblioteki PyTorch Lightning. W tym celu wykorzystamy utworzoną wcześniej klasę `LitNet` dziedziczącą z klasy `lightning.LightningModule`."
      ],
      "metadata": {
        "id": "UGobAgHXvxxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init the network\n",
        "classifier = SimpleNet(model.vector_size, n_classes=2)\n",
        "# Wrap in a lightning module\n",
        "lit_model = LitNet(classifier)"
      ],
      "metadata": {
        "id": "bt6UhJYPqofT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb_logger = WandbLogger(project=\"MyExperiments\")\n",
        "trainer = L.Trainer(max_epochs=num_epochs, logger=wandb_logger)"
      ],
      "metadata": {
        "id": "0zQ8O9O3qhIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(\n",
        "    lit_model,\n",
        "    train_dataloaders=dataloaders['train'],\n",
        "    val_dataloaders=dataloaders['val']\n",
        "    )"
      ],
      "metadata": {
        "id": "VsUs9T_GrS0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(ckpt_path=\"best\", dataloaders=dataloaders['test'])"
      ],
      "metadata": {
        "id": "BEAeaoKtugm3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}